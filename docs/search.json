[
  {
    "objectID": "week02.html",
    "href": "week02.html",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nJoin tables using INNER, LEFT, RIGHT, and FULL JOINs.\nUnderstand the concepts and perform self-joins and cross joins using CROSS JOIN.\nPerform complex data aggregation using GROUP BY and HAVING.\nPerform set operations using UNION, UNION ALL, EXCEPT and INTERSECT. Notebook 2.4\nConstruct subqueries for complex queries using WHERE, IN, EXISTS.\nUsing CTEs to make queries more readable using WITH.\nImporting data from a CSV file using .mode csv and .import.",
    "crumbs": [
      "Content",
      "Week 02: SQL ‚Äì Intermediate Concepts"
    ]
  },
  {
    "objectID": "week02.html#slos-for-week-02",
    "href": "week02.html#slos-for-week-02",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nJoin tables using INNER, LEFT, RIGHT, and FULL JOINs.\nUnderstand the concepts and perform self-joins and cross joins using CROSS JOIN.\nPerform complex data aggregation using GROUP BY and HAVING.\nPerform set operations using UNION, UNION ALL, EXCEPT and INTERSECT. Notebook 2.4\nConstruct subqueries for complex queries using WHERE, IN, EXISTS.\nUsing CTEs to make queries more readable using WITH.\nImporting data from a CSV file using .mode csv and .import.",
    "crumbs": [
      "Content",
      "Week 02: SQL ‚Äì Intermediate Concepts"
    ]
  },
  {
    "objectID": "week02.html#slides-videos-and-application-exercises",
    "href": "week02.html#slides-videos-and-application-exercises",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 02: Slides\n\n\nSummary of the Week\n\n\nLibrary Case Notebook\n\n\nNotes for W02 Notebook\n\n\nMark Simon. (2023). Getting Started with SQL and Databases‚ÄØ: Managing and Manipulating Data with SQL. Apress. - Chapters 4, 5 and 6\n\n\n\n\nHomework 02\n\nInstructions\n\n\n\n\nProject 02\n\nInstructions",
    "crumbs": [
      "Content",
      "Week 02: SQL ‚Äì Intermediate Concepts"
    ]
  },
  {
    "objectID": "week01.html",
    "href": "week01.html",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nExplain the purpose and importance of relational databases.\nDifferentiate between relational databases and other types of data storage.\nQuery data from a single table using SELECT statement.\nSort the result set in ascending and descending order using ORDER BY.\nFilter data according to various conditions using DISTINCT, WHERE, AND, OR, LIMIT/OFFSET, BETWEEN, IN, LIKE and ILIKE, GLOB and IS NULL.\nAnalyze a dataset using simple queries.",
    "crumbs": [
      "Content",
      "Week 01: Introduction to Databases & SQL Basics"
    ]
  },
  {
    "objectID": "week01.html#slos-for-week-01",
    "href": "week01.html#slos-for-week-01",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nExplain the purpose and importance of relational databases.\nDifferentiate between relational databases and other types of data storage.\nQuery data from a single table using SELECT statement.\nSort the result set in ascending and descending order using ORDER BY.\nFilter data according to various conditions using DISTINCT, WHERE, AND, OR, LIMIT/OFFSET, BETWEEN, IN, LIKE and ILIKE, GLOB and IS NULL.\nAnalyze a dataset using simple queries.",
    "crumbs": [
      "Content",
      "Week 01: Introduction to Databases & SQL Basics"
    ]
  },
  {
    "objectID": "week01.html#slides-videos-and-application-exercises",
    "href": "week01.html#slides-videos-and-application-exercises",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 01: Slides\nOnly people at Calvin can access the slides.\n\nSlides\n\n\nSummary of the Week\n\n\nMark Simon. (2023). Getting Started with SQL and Databases‚ÄØ: Managing and Manipulating Data with SQL. Apress. - Chapters 1, 2 and 3\n\n\n\n\nHomework 01\n\nInstructions\n\n\n\n\nProject 01\n\nInstructions",
    "crumbs": [
      "Content",
      "Week 01: Introduction to Databases & SQL Basics"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Course Resources",
    "section": "",
    "text": "Links to websites offering SQL training\n\n\n\n\n\n\nImportant\n\n\n\nThese links were last updated on 02/03/2025. Please let me know if you encounter any broken links.\n\n\n\nReal Python SQL\nSQLZoo\nCodeAcademy\nHackerRank\nLeetCode\nW3Schools\nSQLBolt\nMode\nSQLPad\nLearnSQL\nSQLGuroo\nDB Fiddle"
  },
  {
    "objectID": "week04.html",
    "href": "week04.html",
    "title": "Week 04: Database Design ‚Äì ER Modeling & Schema Refinement (under construction)",
    "section": "",
    "text": "Students will be able to‚Ä¶\n\nAdd conditional logic to queries using CASE.\nCreate and understand the view concept using CREATE VIEW and DROP VIEW.\nDifferentiate between materialized and non-materialized views.\nDesign ER diagrams to model database structures.\nConvert ER models into relational schemas.\nCreate SQL schemas from conceptual designs.\nIdentify and resolve redundancy issues in schemas.",
    "crumbs": [
      "Content",
      "Week 04: Database Design ‚Äì ER Modeling & Schema Refinement (under construction)"
    ]
  },
  {
    "objectID": "week04.html#slos-for-week-04",
    "href": "week04.html#slos-for-week-04",
    "title": "Week 04: Database Design ‚Äì ER Modeling & Schema Refinement (under construction)",
    "section": "",
    "text": "Students will be able to‚Ä¶\n\nAdd conditional logic to queries using CASE.\nCreate and understand the view concept using CREATE VIEW and DROP VIEW.\nDifferentiate between materialized and non-materialized views.\nDesign ER diagrams to model database structures.\nConvert ER models into relational schemas.\nCreate SQL schemas from conceptual designs.\nIdentify and resolve redundancy issues in schemas.",
    "crumbs": [
      "Content",
      "Week 04: Database Design ‚Äì ER Modeling & Schema Refinement (under construction)"
    ]
  },
  {
    "objectID": "week04.html#slides-videos-and-application-exercises",
    "href": "week04.html#slides-videos-and-application-exercises",
    "title": "Week 04: Database Design ‚Äì ER Modeling & Schema Refinement (under construction)",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 04: Slides\n\nSlides\n\n\nNo readings for Week 4.\n\n\n\n\nHomework 04:\n\nInstructions\n\n\n\n\nProject 04:\n\nInstructions\n\n\n\nExam 1\nExam on Friday during class. Bring your laptop. Content: Weeks 1 - 3.",
    "crumbs": [
      "Content",
      "Week 04: Database Design ‚Äì ER Modeling & Schema Refinement (under construction)"
    ]
  },
  {
    "objectID": "week07.html",
    "href": "week07.html",
    "title": "Week 07: Final Project and Course Wrap-Up (under construction)",
    "section": "",
    "text": "By the end of this unit, students will be able to‚Ä¶\n\nDesign and implement a database system from scratch.\nWrite SQL queries to solve real-world data retrieval problems.\nPresent a comprehensive database solution addressing a given scenario.\nCompare different database designs and justify choices.\nDemonstrate proficiency in SQL and database management concepts.\nReflect on the course content and their learning experience.",
    "crumbs": [
      "Content",
      "Week 07: Final Project and Course Wrap-Up (under construction)"
    ]
  },
  {
    "objectID": "week07.html#slos-for-week-07",
    "href": "week07.html#slos-for-week-07",
    "title": "Week 07: Final Project and Course Wrap-Up (under construction)",
    "section": "",
    "text": "By the end of this unit, students will be able to‚Ä¶\n\nDesign and implement a database system from scratch.\nWrite SQL queries to solve real-world data retrieval problems.\nPresent a comprehensive database solution addressing a given scenario.\nCompare different database designs and justify choices.\nDemonstrate proficiency in SQL and database management concepts.\nReflect on the course content and their learning experience.",
    "crumbs": [
      "Content",
      "Week 07: Final Project and Course Wrap-Up (under construction)"
    ]
  },
  {
    "objectID": "week07.html#slides-videos-and-application-exercises",
    "href": "week07.html#slides-videos-and-application-exercises",
    "title": "Week 07: Final Project and Course Wrap-Up (under construction)",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 07: Slides\n\nSlides\n\n\nNo readings for Week 07.\n\n\n\n\nHomework 7:\n\nInstructions\n\n\n\n\nProject 07: Final Project\n\nInstructions",
    "crumbs": [
      "Content",
      "Week 07: Final Project and Course Wrap-Up (under construction)"
    ]
  },
  {
    "objectID": "week02-library.html",
    "href": "week02-library.html",
    "title": "Week 02: Library Survey Tables Case Study",
    "section": "",
    "text": "In the US, the Institute of Museum and Library Services (IMLS) measures library activity as part of its annual Public Libraries Survey. The survey collects data from more than 9000 library administrative entities, defined by the survey as agencies that provide library services to a particular locality. Data includes the number of branches, staff, books, hours open per year, etc. To teach the concepts below, we will build three tables containing the data from the survey related to the years of 2016, 2017 and 2018. For doing so, we read from the CSV files downloaded from their website. More especifically, some columns will be selected in the process to reduce the amount of non used attributes.\nWe are running SQL queries in a Jupyter environment.\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/library.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n\nThis will open our database library.db for us. Don‚Äôt bother yourself with the config details. That is a trick to run the SQL queries in this environment.\nNow we turn to our tables. We have to create 3 tables. Let‚Äôs start with the table for 2018.\n\n%%sql\n-- Creating the 2018 Public Libraries Survey table\n\n-- We drop an old copy of the table, if it exists.\nDROP TABLE IF EXISTS libraries_2018;\n\nCREATE TABLE libraries_2018 (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\n * sqlite:///dbs/w02/library.db\nDone.\nDone.\n\n\n[]\n\n\nThis is an empty table. To fill the table, we need to convert our CSV entries to entitites in our database.\nHere I came up with another trick. I created a subprocess that opens SQLite3 and calls the command to convert a CSV file into a table inside the database. The code is as follows:\n\nimport subprocess\nimport tempfile\nimport os\n\n# Paths and settings\ncsv_path = \"dbs/w02/pls_fy2018_libraries.csv\"\ndb_path = \"dbs/w02/library.db\"\ntable_name = \"libraries_2018\"\n\n# Step 1: Create a temporary CSV file without the header\nwith open(csv_path, 'r', encoding='utf-8') as original, tempfile.NamedTemporaryFile('w', delete=False, newline='', encoding='utf-8') as noheader:\n    next(original)  # skip the header\n    for line in original:\n        noheader.write(line)\n    temp_csv_path = noheader.name\n\n# Step 2: Build the SQLite shell command\nsqlite_cmd = f\"\"\"\n.mode csv\n.import '{temp_csv_path}' {table_name}\n\"\"\"\n\n# Step 3: Run the command with subprocess\nsubprocess.run([\"sqlite3\", db_path], input=sqlite_cmd, text=True)\n\n# Step 4: Clean up the temp file\nos.remove(temp_csv_path)\n\nprint(f\"‚úÖ Imported '{csv_path}' into '{table_name}' in '{db_path}' (header skipped)\")\n\n‚úÖ Imported 'dbs/w02/pls_fy2018_libraries.csv' into 'libraries_2018' in 'dbs/w02/library.db' (header skipped)\n\n\n\nLet‚Äôs see if the data was loaded? Let‚Äôs peak on the 10 first rows.\n\n%%sql\nSELECT * FROM libraries_2018\nLIMIT 10;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\nfscskey\nlibid\nlibname\naddress\ncity\nzip\ncounty\nphone\nc_relatn\nc_legbas\nc_admin\nc_fscs\ngeocode\nlsabound\nstartdate\nenddate\npopu_lsa\npopu_und\ncentlib\nbranlib\nbkmob\ntotstaff\nbkvol\nebook\naudio_ph\naudio_dl\nvideo_ph\nvideo_dl\nec_lo_ot\nsubscrip\nhrs_open\nvisits\nreference\nregbor\ntotcir\nkidcircl\ntotpro\ngpterms\npitusr\nwifisess\nobereg\nstatstru\nstatname\nstataddr\nlongitude\nlatitude\n\n\n\n\nAK\nAK0001\nAK0001-002\nANCHOR POINT PUBLIC LIBRARY\n34020 NORTH FORK ROAD\nANCHOR POINT\n99556\nKENAI PENINSULA\n9072355692\nNO\nNP\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n2057\n2040\n1\n0\n0\n0.67\n18201\n0\n179\n0\n3320\n0\n0\n9\n1245\n6032\n4\n1726\n11316\n2294\n60\n8\n1495\n1182\n08\n00\n00\n00\n-151.825\n59.77965\n\n\nAK\nAK0002\nAK0002-011\nANCHORAGE PUBLIC LIBRARY\n3600 DENALI STREET\nANCHORAGE\n99503\nANCHORAGE\n9073432892\nNO\nCO\nMO\nY\nMA1\nN\n1/1/17\n12/31/17\n295365\n292940\n1\n4\n0\n76.65\n370812\n21587\n30963\n12992\n76404\n0\n14\n7311\n11400\n723272\n54306\n135828\n1574942\n553651\n1924\n165\n126846\n90135\n08\n00\n00\n00\n-149.876\n61.18744\n\n\nAK\nAK0003\nAK0003-002\nANDERSON COMMUNITY LIBRARY\n101 FIRST STREET\nANDERSON\n99744\nDENALI\n9075822628\nNO\nCI\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n269\n267\n1\n0\n0\n0.75\n15314\n0\n201\n0\n1403\n0\n0\n0\n480\n592\n300\n113\n1137\n264\n4\n5\n225\n0\n08\n00\n00\n00\n-149.187\n64.34363\n\n\nAK\nAK0006\nAK0006-002\nKUSKOKWIM CONSORTIUM LIBRARY\n420 CHIEF EDDIE HOFFMAN HIGHWAY\nBETHEL\n99559\nBETHEL\n9075434516\nNO\nMJ\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n6135\n6085\n1\n0\n0\n3\n34860\n21587\n425\n12992\n3782\n0\n0\n5\n2040\n51000\n1530\n1912\n14067\n3746\n406\n8\n6600\n5716\n08\n00\n00\n00\n-161.771\n60.79114\n\n\nAK\nAK0007\nAK0007-002\nBIG LAKE PUBLIC LIBRARY\n3140 SOUTH BIG LAKE ROAD\nBIG LAKE\n99652\nMATANUSKA-SUSITNA\n9078617635\nNO\nCO\nSO\nY\nCO1\nN\n7/1/17\n6/30/18\n12847\n12742\n1\n0\n0\n3\n28698\n21587\n2140\n12992\n3805\n0\n0\n47\n2551\n62249\n887\n2890\n36670\n15691\n363\n18\n15022\n8125\n08\n00\n00\n00\n-149.819\n61.5475\n\n\nAK\nAK0008\nAK0008-002\nCANTWELL COMMUNITY LIBRARY\n1 SCHOOL ROAD\nCANTWELL\n99729\nDENALI\n9077682372\nNO\nNP\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n202\n200\n1\n0\n0\n0.8\n10376\n21587\n275\n12992\n562\n0\n0\n15\n720\n2500\n390\n183\n2828\n1198\n45\n1\n50\n95\n08\n00\n00\n00\n-148.9\n63.3912\n\n\nAK\nAK0011\nAK0011-002\nCHINIAK PUBLIC LIBRARY\n43318 SPRUCE WAY\nCHINIAK\n99615\nKODIAK ISLAND\n9075120880\nNO\nNP\nSO\nN\nCI1\nN\n7/1/17\n6/30/18\n44\n44\n1\n0\n0\n0\n2300\n21587\n0\n12992\n257\n0\n0\n18\n132\n302\n0\n39\n465\n301\n27\n2\n75\n220\n08\n00\n00\n00\n-152.231\n57.61245\n\n\nAK\nAK0014\nAK0014-002\nCOLD BAY PUBLIC LIBRARY\n10 BARANOV ROAD\nCOLD BAY\n99571\nALEUTIANS EAST\n9075322878\nNO\nNP\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n63\n62\n1\n0\n0\n0.25\n3226\n0\n445\n0\n2673\n0\n0\n0\n400\n1080\n31\n36\n121\n11\n5\n4\n235\n893\n08\n00\n00\n00\n-160.693\n55.69687\n\n\nAK\nAK0015\nAK0015-002\nCOOPER LANDING COMMUNITY LIBRARY\n18511 BEAN CREEK ROAD\nCOOPER LANDING\n99572\nKENAI PENINSULA\n9075951241\nNO\nNP\nSO\nN\nCI1\nN\n7/1/17\n6/30/18\n265\n263\n1\n0\n0\n0\n4163\n0\n192\n0\n926\n0\n0\n1\n1092\n2452\n70\n834\n2232\n772\n11\n4\n395\n357\n08\n00\n00\n00\n-149.823\n60.49404\n\n\nAK\nAK0016\nAK0016-002\nCORDOVA PUBLIC LIBRARY\n601 FIRST STREET\nCORDOVA\n99574\nVALDEZ-CORDOVA\n9074246667\nNO\nCI\nSO\nY\nCI1\nN\n1/1/17\n12/31/17\n2360\n2341\n1\n0\n0\n5\n17888\n21587\n560\n12992\n1200\n0\n0\n48\n2575\n20844\n1024\n2527\n14435\n4298\n282\n6\n5357\n6997\n08\n00\n00\n00\n-145.758\n60.54716\n\n\n\n\n\nNow, lets count how many rows are in this table.\n\n%%sql\nSELECT count(*) FROM libraries_2018;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\ncount(*)\n\n\n\n\n9261\n\n\n\n\n\n\nThe same should be done for the years 2016 and 2017. The code below is long, but identical to what we‚Äôve done above.\n\n%%sql\n\n-- Creating the 2016 Public Libraries Survey table\n\n-- We drop an old copy of the table, if it exists.\nDROP TABLE IF EXISTS libraries_2016;\nDROP TABLE IF EXISTS libraries_2017;\n\nCREATE TABLE libraries_2016 (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\nCREATE TABLE libraries_2017 (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\n * sqlite:///dbs/w02/library.db\nDone.\nDone.\nDone.\nDone.\n\n\n[]\n\n\n\n# Importing the 2017 Public Libraries Survey data\n\n# Paths and settings\ncsv_path = \"dbs/w02/pls_fy2017_libraries.csv\"\ndb_path = \"dbs/w02/library.db\"\ntable_name = \"libraries_2017\"\n\n# Step 1: Create a temporary CSV file without the header\nwith open(csv_path, 'r', encoding='utf-8') as original, tempfile.NamedTemporaryFile('w', delete=False, newline='', encoding='utf-8') as noheader:\n    next(original)  # skip the header\n    for line in original:\n        noheader.write(line)\n    temp_csv_path = noheader.name\n\n# Step 2: Build the SQLite shell command\nsqlite_cmd = f\"\"\"\n.mode csv\n.import '{temp_csv_path}' {table_name}\n\"\"\"\n\n# Step 3: Run the command with subprocess\nsubprocess.run([\"sqlite3\", db_path], input=sqlite_cmd, text=True)\n\n# Step 4: Clean up the temp file\nos.remove(temp_csv_path)\n\nprint(f\"‚úÖ Imported '{csv_path}' into '{table_name}' in '{db_path}' (header skipped)\")\n\n‚úÖ Imported 'dbs/w02/pls_fy2017_libraries.csv' into 'libraries_2017' in 'dbs/w02/library.db' (header skipped)\n\n\n\n# Importing the 2016 Public Libraries Survey data\n\n# Paths and settings\ncsv_path = \"dbs/w02/pls_fy2016_libraries.csv\"\ndb_path = \"dbs/w02/library.db\"\ntable_name = \"libraries_2016\"\n\n# Step 1: Create a temporary CSV file without the header\nwith open(csv_path, 'r', encoding='utf-8') as original, tempfile.NamedTemporaryFile('w', delete=False, newline='', encoding='utf-8') as noheader:\n    next(original)  # skip the header\n    for line in original:\n        noheader.write(line)\n    temp_csv_path = noheader.name\n\n# Step 2: Build the SQLite shell command\nsqlite_cmd = f\"\"\"\n.mode csv\n.import '{temp_csv_path}' {table_name}\n\"\"\"\n\n# Step 3: Run the command with subprocess\nsubprocess.run([\"sqlite3\", db_path], input=sqlite_cmd, text=True)\n\n# Step 4: Clean up the temp file\nos.remove(temp_csv_path)\n\nprint(f\"‚úÖ Imported '{csv_path}' into '{table_name}' in '{db_path}' (header skipped)\")\n\n‚úÖ Imported 'dbs/w02/pls_fy2016_libraries.csv' into 'libraries_2016' in 'dbs/w02/library.db' (header skipped)\n\n\n\nLet‚Äôs check the rows count for each of the tables now.\n\n%%sql\n    SELECT 2016 AS 'Year', count(*) AS NumRows FROM libraries_2016\nUNION ALL\n    SELECT 2017, count(*) AS NumRows FROM libraries_2017\nUNION ALL\n    SELECT 2018, count(*) AS NumRows FROM libraries_2018;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nYear\nNumRows\n\n\n\n\n2016\n9252\n\n\n2017\n9245\n\n\n2018\n9261"
  },
  {
    "objectID": "week02-library.html#creating-the-library-survey-tables",
    "href": "week02-library.html#creating-the-library-survey-tables",
    "title": "Week 02: Library Survey Tables Case Study",
    "section": "",
    "text": "In the US, the Institute of Museum and Library Services (IMLS) measures library activity as part of its annual Public Libraries Survey. The survey collects data from more than 9000 library administrative entities, defined by the survey as agencies that provide library services to a particular locality. Data includes the number of branches, staff, books, hours open per year, etc. To teach the concepts below, we will build three tables containing the data from the survey related to the years of 2016, 2017 and 2018. For doing so, we read from the CSV files downloaded from their website. More especifically, some columns will be selected in the process to reduce the amount of non used attributes.\nWe are running SQL queries in a Jupyter environment.\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/library.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n\nThis will open our database library.db for us. Don‚Äôt bother yourself with the config details. That is a trick to run the SQL queries in this environment.\nNow we turn to our tables. We have to create 3 tables. Let‚Äôs start with the table for 2018.\n\n%%sql\n-- Creating the 2018 Public Libraries Survey table\n\n-- We drop an old copy of the table, if it exists.\nDROP TABLE IF EXISTS libraries_2018;\n\nCREATE TABLE libraries_2018 (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\n * sqlite:///dbs/w02/library.db\nDone.\nDone.\n\n\n[]\n\n\nThis is an empty table. To fill the table, we need to convert our CSV entries to entitites in our database.\nHere I came up with another trick. I created a subprocess that opens SQLite3 and calls the command to convert a CSV file into a table inside the database. The code is as follows:\n\nimport subprocess\nimport tempfile\nimport os\n\n# Paths and settings\ncsv_path = \"dbs/w02/pls_fy2018_libraries.csv\"\ndb_path = \"dbs/w02/library.db\"\ntable_name = \"libraries_2018\"\n\n# Step 1: Create a temporary CSV file without the header\nwith open(csv_path, 'r', encoding='utf-8') as original, tempfile.NamedTemporaryFile('w', delete=False, newline='', encoding='utf-8') as noheader:\n    next(original)  # skip the header\n    for line in original:\n        noheader.write(line)\n    temp_csv_path = noheader.name\n\n# Step 2: Build the SQLite shell command\nsqlite_cmd = f\"\"\"\n.mode csv\n.import '{temp_csv_path}' {table_name}\n\"\"\"\n\n# Step 3: Run the command with subprocess\nsubprocess.run([\"sqlite3\", db_path], input=sqlite_cmd, text=True)\n\n# Step 4: Clean up the temp file\nos.remove(temp_csv_path)\n\nprint(f\"‚úÖ Imported '{csv_path}' into '{table_name}' in '{db_path}' (header skipped)\")\n\n‚úÖ Imported 'dbs/w02/pls_fy2018_libraries.csv' into 'libraries_2018' in 'dbs/w02/library.db' (header skipped)\n\n\n\nLet‚Äôs see if the data was loaded? Let‚Äôs peak on the 10 first rows.\n\n%%sql\nSELECT * FROM libraries_2018\nLIMIT 10;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\nfscskey\nlibid\nlibname\naddress\ncity\nzip\ncounty\nphone\nc_relatn\nc_legbas\nc_admin\nc_fscs\ngeocode\nlsabound\nstartdate\nenddate\npopu_lsa\npopu_und\ncentlib\nbranlib\nbkmob\ntotstaff\nbkvol\nebook\naudio_ph\naudio_dl\nvideo_ph\nvideo_dl\nec_lo_ot\nsubscrip\nhrs_open\nvisits\nreference\nregbor\ntotcir\nkidcircl\ntotpro\ngpterms\npitusr\nwifisess\nobereg\nstatstru\nstatname\nstataddr\nlongitude\nlatitude\n\n\n\n\nAK\nAK0001\nAK0001-002\nANCHOR POINT PUBLIC LIBRARY\n34020 NORTH FORK ROAD\nANCHOR POINT\n99556\nKENAI PENINSULA\n9072355692\nNO\nNP\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n2057\n2040\n1\n0\n0\n0.67\n18201\n0\n179\n0\n3320\n0\n0\n9\n1245\n6032\n4\n1726\n11316\n2294\n60\n8\n1495\n1182\n08\n00\n00\n00\n-151.825\n59.77965\n\n\nAK\nAK0002\nAK0002-011\nANCHORAGE PUBLIC LIBRARY\n3600 DENALI STREET\nANCHORAGE\n99503\nANCHORAGE\n9073432892\nNO\nCO\nMO\nY\nMA1\nN\n1/1/17\n12/31/17\n295365\n292940\n1\n4\n0\n76.65\n370812\n21587\n30963\n12992\n76404\n0\n14\n7311\n11400\n723272\n54306\n135828\n1574942\n553651\n1924\n165\n126846\n90135\n08\n00\n00\n00\n-149.876\n61.18744\n\n\nAK\nAK0003\nAK0003-002\nANDERSON COMMUNITY LIBRARY\n101 FIRST STREET\nANDERSON\n99744\nDENALI\n9075822628\nNO\nCI\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n269\n267\n1\n0\n0\n0.75\n15314\n0\n201\n0\n1403\n0\n0\n0\n480\n592\n300\n113\n1137\n264\n4\n5\n225\n0\n08\n00\n00\n00\n-149.187\n64.34363\n\n\nAK\nAK0006\nAK0006-002\nKUSKOKWIM CONSORTIUM LIBRARY\n420 CHIEF EDDIE HOFFMAN HIGHWAY\nBETHEL\n99559\nBETHEL\n9075434516\nNO\nMJ\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n6135\n6085\n1\n0\n0\n3\n34860\n21587\n425\n12992\n3782\n0\n0\n5\n2040\n51000\n1530\n1912\n14067\n3746\n406\n8\n6600\n5716\n08\n00\n00\n00\n-161.771\n60.79114\n\n\nAK\nAK0007\nAK0007-002\nBIG LAKE PUBLIC LIBRARY\n3140 SOUTH BIG LAKE ROAD\nBIG LAKE\n99652\nMATANUSKA-SUSITNA\n9078617635\nNO\nCO\nSO\nY\nCO1\nN\n7/1/17\n6/30/18\n12847\n12742\n1\n0\n0\n3\n28698\n21587\n2140\n12992\n3805\n0\n0\n47\n2551\n62249\n887\n2890\n36670\n15691\n363\n18\n15022\n8125\n08\n00\n00\n00\n-149.819\n61.5475\n\n\nAK\nAK0008\nAK0008-002\nCANTWELL COMMUNITY LIBRARY\n1 SCHOOL ROAD\nCANTWELL\n99729\nDENALI\n9077682372\nNO\nNP\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n202\n200\n1\n0\n0\n0.8\n10376\n21587\n275\n12992\n562\n0\n0\n15\n720\n2500\n390\n183\n2828\n1198\n45\n1\n50\n95\n08\n00\n00\n00\n-148.9\n63.3912\n\n\nAK\nAK0011\nAK0011-002\nCHINIAK PUBLIC LIBRARY\n43318 SPRUCE WAY\nCHINIAK\n99615\nKODIAK ISLAND\n9075120880\nNO\nNP\nSO\nN\nCI1\nN\n7/1/17\n6/30/18\n44\n44\n1\n0\n0\n0\n2300\n21587\n0\n12992\n257\n0\n0\n18\n132\n302\n0\n39\n465\n301\n27\n2\n75\n220\n08\n00\n00\n00\n-152.231\n57.61245\n\n\nAK\nAK0014\nAK0014-002\nCOLD BAY PUBLIC LIBRARY\n10 BARANOV ROAD\nCOLD BAY\n99571\nALEUTIANS EAST\n9075322878\nNO\nNP\nSO\nY\nCI1\nN\n7/1/17\n6/30/18\n63\n62\n1\n0\n0\n0.25\n3226\n0\n445\n0\n2673\n0\n0\n0\n400\n1080\n31\n36\n121\n11\n5\n4\n235\n893\n08\n00\n00\n00\n-160.693\n55.69687\n\n\nAK\nAK0015\nAK0015-002\nCOOPER LANDING COMMUNITY LIBRARY\n18511 BEAN CREEK ROAD\nCOOPER LANDING\n99572\nKENAI PENINSULA\n9075951241\nNO\nNP\nSO\nN\nCI1\nN\n7/1/17\n6/30/18\n265\n263\n1\n0\n0\n0\n4163\n0\n192\n0\n926\n0\n0\n1\n1092\n2452\n70\n834\n2232\n772\n11\n4\n395\n357\n08\n00\n00\n00\n-149.823\n60.49404\n\n\nAK\nAK0016\nAK0016-002\nCORDOVA PUBLIC LIBRARY\n601 FIRST STREET\nCORDOVA\n99574\nVALDEZ-CORDOVA\n9074246667\nNO\nCI\nSO\nY\nCI1\nN\n1/1/17\n12/31/17\n2360\n2341\n1\n0\n0\n5\n17888\n21587\n560\n12992\n1200\n0\n0\n48\n2575\n20844\n1024\n2527\n14435\n4298\n282\n6\n5357\n6997\n08\n00\n00\n00\n-145.758\n60.54716\n\n\n\n\n\nNow, lets count how many rows are in this table.\n\n%%sql\nSELECT count(*) FROM libraries_2018;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\ncount(*)\n\n\n\n\n9261\n\n\n\n\n\n\nThe same should be done for the years 2016 and 2017. The code below is long, but identical to what we‚Äôve done above.\n\n%%sql\n\n-- Creating the 2016 Public Libraries Survey table\n\n-- We drop an old copy of the table, if it exists.\nDROP TABLE IF EXISTS libraries_2016;\nDROP TABLE IF EXISTS libraries_2017;\n\nCREATE TABLE libraries_2016 (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\nCREATE TABLE libraries_2017 (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\n * sqlite:///dbs/w02/library.db\nDone.\nDone.\nDone.\nDone.\n\n\n[]\n\n\n\n# Importing the 2017 Public Libraries Survey data\n\n# Paths and settings\ncsv_path = \"dbs/w02/pls_fy2017_libraries.csv\"\ndb_path = \"dbs/w02/library.db\"\ntable_name = \"libraries_2017\"\n\n# Step 1: Create a temporary CSV file without the header\nwith open(csv_path, 'r', encoding='utf-8') as original, tempfile.NamedTemporaryFile('w', delete=False, newline='', encoding='utf-8') as noheader:\n    next(original)  # skip the header\n    for line in original:\n        noheader.write(line)\n    temp_csv_path = noheader.name\n\n# Step 2: Build the SQLite shell command\nsqlite_cmd = f\"\"\"\n.mode csv\n.import '{temp_csv_path}' {table_name}\n\"\"\"\n\n# Step 3: Run the command with subprocess\nsubprocess.run([\"sqlite3\", db_path], input=sqlite_cmd, text=True)\n\n# Step 4: Clean up the temp file\nos.remove(temp_csv_path)\n\nprint(f\"‚úÖ Imported '{csv_path}' into '{table_name}' in '{db_path}' (header skipped)\")\n\n‚úÖ Imported 'dbs/w02/pls_fy2017_libraries.csv' into 'libraries_2017' in 'dbs/w02/library.db' (header skipped)\n\n\n\n# Importing the 2016 Public Libraries Survey data\n\n# Paths and settings\ncsv_path = \"dbs/w02/pls_fy2016_libraries.csv\"\ndb_path = \"dbs/w02/library.db\"\ntable_name = \"libraries_2016\"\n\n# Step 1: Create a temporary CSV file without the header\nwith open(csv_path, 'r', encoding='utf-8') as original, tempfile.NamedTemporaryFile('w', delete=False, newline='', encoding='utf-8') as noheader:\n    next(original)  # skip the header\n    for line in original:\n        noheader.write(line)\n    temp_csv_path = noheader.name\n\n# Step 2: Build the SQLite shell command\nsqlite_cmd = f\"\"\"\n.mode csv\n.import '{temp_csv_path}' {table_name}\n\"\"\"\n\n# Step 3: Run the command with subprocess\nsubprocess.run([\"sqlite3\", db_path], input=sqlite_cmd, text=True)\n\n# Step 4: Clean up the temp file\nos.remove(temp_csv_path)\n\nprint(f\"‚úÖ Imported '{csv_path}' into '{table_name}' in '{db_path}' (header skipped)\")\n\n‚úÖ Imported 'dbs/w02/pls_fy2016_libraries.csv' into 'libraries_2016' in 'dbs/w02/library.db' (header skipped)\n\n\n\nLet‚Äôs check the rows count for each of the tables now.\n\n%%sql\n    SELECT 2016 AS 'Year', count(*) AS NumRows FROM libraries_2016\nUNION ALL\n    SELECT 2017, count(*) AS NumRows FROM libraries_2017\nUNION ALL\n    SELECT 2018, count(*) AS NumRows FROM libraries_2018;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nYear\nNumRows\n\n\n\n\n2016\n9252\n\n\n2017\n9245\n\n\n2018\n9261"
  },
  {
    "objectID": "week02-library.html#counting-distinct-values-in-a-column",
    "href": "week02-library.html#counting-distinct-values-in-a-column",
    "title": "Week 02: Library Survey Tables Case Study",
    "section": "1.1 Counting Distinct Values in a Column",
    "text": "1.1 Counting Distinct Values in a Column\nWe can combine DISTINCT with combinations of values like count(). This will return a count of distinct values from a column.\n\n%%sql\nSELECT count(libname)\nFROM libraries_2017;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\ncount(libname)\n\n\n\n\n9245\n\n\n\n\n\n\n%%sql\nSELECT count(DISTINCT libname)\nFROM libraries_2017;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\ncount(DISTINCT libname)\n\n\n\n\n8455\n\n\n\n\n\n\nRemoving duplicates reduces the number of library names. It happens that some libraries share their names with other agencies. We will see how we can see the duplicates soon."
  },
  {
    "objectID": "week02-library.html#finding-maximum-and-minimum-values-using-max-and-min",
    "href": "week02-library.html#finding-maximum-and-minimum-values-using-max-and-min",
    "title": "Week 02: Library Survey Tables Case Study",
    "section": "1.2 Finding Maximum and Minimum Values using max() and min()",
    "text": "1.2 Finding Maximum and Minimum Values using max() and min()\nThe max() and min() funtions return the largest and smallest values in a column. In our case, we will be using them to detect some annomalies in the data. Let‚Äôs check the number of visits for 2018.\n\n%%sql\nSELECT max(visits), min(visits)\nFROM libraries_2018;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nmax(visits)\nmin(visits)\n\n\n\n\n16686945\n-3\n\n\n\n\n\n\nThe value of -3 is unexpected. It happens that the negative values for this database indicate ‚Äúnot applicable‚Äù, used when a library has closed temporarily or permanently. This is a terrible way of coding missing data, but we can cope with that.\nWe could use WHERE min(visits &gt; 0) to guarantee that only positive numbers are in the game.\nA better way of handling these situations would be using NULL values and adding a column to hold text explaining why the value is NULL."
  },
  {
    "objectID": "week02-library.html#aggregating-with-group-by",
    "href": "week02-library.html#aggregating-with-group-by",
    "title": "Week 02: Library Survey Tables Case Study",
    "section": "1.3 Aggregating with GROUP BY",
    "text": "1.3 Aggregating with GROUP BY\nWe can use the GROUP BY clause to group rows that have the same values in specified columns into summary rows. The GROUP BY statement is often used with aggregate functions like COUNT(), SUM(), AVG(), etc., to perform operations on each group of data.\nLet‚Äôs see how many libraries are in each state. But first, let‚Äôs check which states are in the database.\n\n%%sql\nSELECT stabr\nFROM libraries_2018\nGROUP BY stabr\nORDER BY stabr;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\n\n\n\n\nAK\n\n\nAL\n\n\nAR\n\n\nAS\n\n\nAZ\n\n\nCA\n\n\nCO\n\n\nCT\n\n\nDC\n\n\nDE\n\n\nFL\n\n\nGA\n\n\nGU\n\n\nHI\n\n\nIA\n\n\nID\n\n\nIL\n\n\nIN\n\n\nKS\n\n\nKY\n\n\nLA\n\n\nMA\n\n\nMD\n\n\nME\n\n\nMI\n\n\nMN\n\n\nMO\n\n\nMP\n\n\nMS\n\n\nMT\n\n\nNC\n\n\nND\n\n\nNE\n\n\nNH\n\n\nNJ\n\n\nNM\n\n\nNV\n\n\nNY\n\n\nOH\n\n\nOK\n\n\nOR\n\n\nPA\n\n\nRI\n\n\nSC\n\n\nSD\n\n\nTN\n\n\nTX\n\n\nUT\n\n\nVA\n\n\nVI\n\n\nVT\n\n\nWA\n\n\nWI\n\n\nWV\n\n\nWY\n\n\n\n\n\n\nNotice there are no duplicates in state names. Those are the 50 states plus Washington D.C. and several U.S. territories. We don‚Äôt have to worry about duplicates in this case.\nWe could also have grouped by city and state, using two columns instead of one. Let‚Äôs see how would that work.\n\n%%sql\nSELECT city, stabr\nFROM libraries_2018\nGROUP BY city, stabr\nORDER BY city, stabr\nLIMIT 20;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\ncity\nstabr\n\n\n\n\nABBEVILLE\nAL\n\n\nABBEVILLE\nLA\n\n\nABBEVILLE\nSC\n\n\nABBOTSFORD\nWI\n\n\nABERDEEN\nID\n\n\nABERDEEN\nSD\n\n\nABERNATHY\nTX\n\n\nABILENE\nKS\n\n\nABILENE\nTX\n\n\nABINGDON\nIL\n\n\nABINGDON\nVA\n\n\nABINGTON\nCT\n\n\nABINGTON\nMA\n\n\nABINGTON\nPA\n\n\nABIQUIU\nNM\n\n\nABSECON\nNJ\n\n\nACCOMAC\nVA\n\n\nACKERMAN\nMS\n\n\nACKLEY\nIA\n\n\nACTON\nMA\n\n\n\n\n\n\nWe will limit the number of rows to 10, so we can see the result. The LIMIT clause is used to specify the maximum number of records to return. As you can see, the results are sorted by the first column, which is the city name and then by the state name. The ORDER BY clause is used to sort the result set in ascending or descending order. By default, it sorts in ascending order. We could have used the DESC keyword to sort in descending order. I will leave this as an exercise for you.\nBy combinint GROUP BY with an aggregate function, we can get the number of libraries in each state. Let‚Äôs see how many libraries are in each state.\n\n%%sql\nSELECT stabr, count(*) as total\nFROM libraries_2018\nGROUP BY stabr\nORDER BY total DESC\nLIMIT 20;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\ntotal\n\n\n\n\nNY\n756\n\n\nIL\n623\n\n\nTX\n560\n\n\nIA\n544\n\n\nPA\n451\n\n\nMI\n398\n\n\nWI\n381\n\n\nMA\n369\n\n\nKS\n325\n\n\nNJ\n295\n\n\nME\n263\n\n\nOH\n251\n\n\nNE\n245\n\n\nIN\n236\n\n\nNH\n225\n\n\nAL\n224\n\n\nCA\n218\n\n\nCT\n192\n\n\nTN\n186\n\n\nVT\n184\n\n\n\n\n\n\nThis is returning the values in the stabrcolumn and the count of how many rows have a given stabr value. The COUNT(*) function counts all rows in each group. The GROUP BY clause groups the result set by the stabr column, and the ORDER BY clause sorts the result set by the count of libraries in descending order.\nLibrary agencies can have many branches. Not all of them will provide an outlet for the public to walk in and borrow books. Some of them are just a warehouse for books, or a place to store the books that are not in use. We can see how many branches are in each state by checking the centlib and branlib columns. You can use the SUM() function in this case. This will be left as an exercise for you.\nWe can also use GROUP BY to group by multiple columns. For example, we can verify how many libraries changed their addresses by state. The column stataddr contains a code indicating whether the agency‚Äôs address changed or not. The code is as follows:\n\n00 - No change\n07 - Moved to a new address\n15 - Minor address change\n\nThe code below will show how many libraries changed their address by state.\n\n%%sql\nSELECT stabr, stataddr, count(*) as total\nFROM libraries_2018\nGROUP BY stabr, stataddr\nORDER BY stabr, stataddr\nLIMIT 20;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\nstataddr\ntotal\n\n\n\n\nAK\n00\n82\n\n\nAL\n00\n220\n\n\nAL\n07\n3\n\n\nAL\n15\n1\n\n\nAR\n00\n58\n\n\nAR\n07\n1\n\n\nAR\n15\n1\n\n\nAS\n00\n1\n\n\nAZ\n00\n88\n\n\nAZ\n15\n1\n\n\nCA\n00\n180\n\n\nCA\n07\n2\n\n\nCA\n15\n36\n\n\nCO\n00\n113\n\n\nCT\n00\n190\n\n\nCT\n07\n1\n\n\nCT\n15\n1\n\n\nDC\n00\n1\n\n\nDE\n00\n21\n\n\nFL\n00\n79\n\n\n\n\n\n\nAs expected, most libraries did not change their address.\n\nüìô Visits over the years\nWe saw before some negative numbers in the visits column due to the way data was collected. Now we turn to see the trends in library visits over the years. We will use the SUM() function to get the total number of visits for each year. The code below will show how many visits were made in each year. We will discard the negative values for this analysis. The SUM() function will ignore the negative values, so we don‚Äôt have to worry about them.\n\n%%sql\nSELECT sum(visits) AS visits_2018\nFROM libraries_2018\nWHERE visits &gt; 0;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nvisits_2018\n\n\n\n\n1292348697\n\n\n\n\n\n\n%%sql\nSELECT sum(visits) AS visits_2017\nFROM libraries_2017\nWHERE visits &gt; 0;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nvisits_2017\n\n\n\n\n1319803999\n\n\n\n\n\n\n%%sql\nSELECT sum(visits) AS visits_2016\nFROM libraries_2016\nWHERE visits &gt; 0;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nvisits_2016\n\n\n\n\n1355648987\n\n\n\n\n\n\nWe went from 1.36 billion visits in 2016 to 1.32 billion in 2017, and then to 1.29 billion in 2018. This is a decrease of about 5% over the three years.\nBut we know that the number of libraries change as they close or open. To have a better idea of the trend, we will only consider libraries present in the three years. We can do this by using the INNER JOIN clause. The code below will show how many visits were made in each year, but only for libraries that were present in all three years.\n\n%%sql\nSELECT sum(pls18.visits) AS visits_2018,\n       sum(pls17.visits) AS visits_2017,\n       sum(pls16.visits) AS visits_2016\nFROM libraries_2018 AS pls18\n    JOIN libraries_2017 AS pls17 ON pls18.fscskey = pls17.fscskey\n    JOIN libraries_2016 AS pls16 ON pls18.fscskey = pls16.fscskey\nWHERE pls18.visits &gt;= 0\n  AND pls17.visits &gt;= 0\n  AND pls16.visits &gt;= 0;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nvisits_2018\nvisits_2017\nvisits_2016\n\n\n\n\n1278148838\n1319325387\n1355078384\n\n\n\n\n\n\nThe results didn‚Äôt change much. We can also take a look at the number of wifi accesses the year in the same way we did for the visitors.\n\n%%sql\nSELECT sum(pls18.wifisess) AS wifisess_2018,\n       sum(pls17.wifisess) AS wifisess_2017,\n       sum(pls16.wifisess) AS wifisess_2016\nFROM libraries_2018 AS pls18\n    JOIN libraries_2017 AS pls17 ON pls18.fscskey = pls17.fscskey\n    JOIN libraries_2016 AS pls16 ON pls18.fscskey = pls16.fscskey\nWHERE pls18.wifisess &gt;= 0\n  AND pls17.wifisess &gt;= 0\n  AND pls16.wifisess &gt;= 0;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nwifisess_2018\nwifisess_2017\nwifisess_2016\n\n\n\n\n349767271\n311336231\n234926102\n\n\n\n\n\n\nEven though the number of visitors decreased, the number of wifi accesses increased. This is a clear indication that people are using the library for more than just borrowing books. They are also using it as a place to study and work.\nTo investigate if the decrease in the number of visitors is a trend in all regions, we must group by state. The code below will show how many visits were made in each year, but only for libraries that were present in all three years.\n\n%%sql\nSELECT  pls2018.stabr,\n        sum(pls2018.visits) AS visits_2018,\n        sum(pls2017.visits) AS visits_2017,\n        sum(pls2016.visits) AS visits_2016,\n        round ( ( \n                 (sum(pls2018.visits) - sum(pls2017.visits) ) * 1.0 / sum(pls2017.visits) ) * 100, 1\n               ) AS visits_ratio_2018_2017,\n        round ( ( (sum(pls2017.visits) - sum(pls2016.visits) ) * 1.0 / \n                 sum(pls2016.visits) ) * 100, 1) AS visits_ratio_2017_2016\nFROM libraries_2018 AS pls2018\n    JOIN libraries_2017 AS pls2017 ON pls2018.fscskey = pls2017.fscskey\n    JOIN libraries_2016 AS pls2016 ON pls2018.fscskey = pls2016.fscskey\nWHERE pls2018.visits &gt;= 0\n  AND pls2017.visits &gt;= 0\n  AND pls2016.visits &gt;= 0\nGROUP BY pls2018.stabr\nORDER BY visits_ratio_2018_2017 DESC;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\nvisits_2018\nvisits_2017\nvisits_2016\nvisits_ratio_2018_2017\nvisits_ratio_2017_2016\n\n\n\n\nSD\n3824804\n3699212\n3722376\n3.4\n-0.6\n\n\nMT\n4332900\n4215484\n4298268\n2.8\n-1.9\n\n\nFL\n68423689\n66697122\n70991029\n2.6\n-6.0\n\n\nND\n2216377\n2162189\n2201730\n2.5\n-1.8\n\n\nID\n8179077\n8029503\n8597955\n1.9\n-6.6\n\n\nDC\n3632539\n3593201\n3930763\n1.1\n-8.6\n\n\nUT\n15326963\n15295494\n16096911\n0.2\n-5.0\n\n\nNH\n7045010\n7028800\n7236567\n0.2\n-2.9\n\n\nME\n6746380\n6731768\n6811441\n0.2\n-1.2\n\n\nDE\n4122181\n4117904\n4125899\n0.1\n-0.2\n\n\nOK\n13399265\n13491194\n13112511\n-0.7\n2.9\n\n\nWY\n3338772\n3367413\n3536788\n-0.9\n-4.8\n\n\nMA\n39926583\n40453003\n40427356\n-1.3\n0.1\n\n\nWA\n37338635\n37916034\n38634499\n-1.5\n-1.9\n\n\nMN\n22952388\n23326303\n24033731\n-1.6\n-2.9\n\n\nNM\n6908686\n7036582\n7178428\n-1.8\n-2.0\n\n\nVA\n33913162\n34563079\n35649602\n-1.9\n-3.0\n\n\nKS\n13483333\n13737900\n13699223\n-1.9\n0.3\n\n\nNY\n97921323\n100012193\n103081304\n-2.1\n-3.0\n\n\nWI\n30097183\n30865470\n31442577\n-2.5\n-1.8\n\n\nAL\n14188647\n14583055\n15637164\n-2.7\n-6.7\n\n\nMI\n44758918\n46052561\n46734166\n-2.8\n-1.5\n\n\nCO\n31085356\n31975615\n32011432\n-2.8\n-0.1\n\n\nNJ\n40947978\n42181061\n42429576\n-2.9\n-0.6\n\n\nCA\n146656984\n151056672\n155613529\n-2.9\n-2.9\n\n\nCT\n20423515\n21051597\n21603777\n-3.0\n-2.6\n\n\nRI\n5490076\n5669309\n5778025\n-3.2\n-1.9\n\n\nPA\n40885876\n42243049\n44105513\n-3.2\n-4.2\n\n\nOR\n19592295\n20244499\n20391927\n-3.2\n-0.7\n\n\nIN\n30836051\n31849195\n33363879\n-3.2\n-4.5\n\n\nIA\n16674976\n17245764\n17753953\n-3.3\n-2.9\n\n\nNV\n9334070\n9684935\n9733359\n-3.6\n-0.5\n\n\nNE\n7449868\n7726127\n7873829\n-3.6\n-1.9\n\n\nVT\n3526357\n3673501\n3721332\n-4.0\n-1.3\n\n\nSC\n13989511\n14567585\n15802934\n-4.0\n-7.8\n\n\nAK\n3268073\n3402486\n3467234\n-4.0\n-1.9\n\n\nIL\n63466887\n66166082\n67336230\n-4.1\n-1.7\n\n\nNC\n31263894\n32621293\n33605264\n-4.2\n-2.9\n\n\nMD\n24976429\n26089963\n27481583\n-4.3\n-5.1\n\n\nAZ\n23439707\n24584201\n25315276\n-4.7\n-2.9\n\n\nOH\n68176967\n71895854\n74119719\n-5.2\n-3.0\n\n\nWV\n4944242\n5231251\n5231443\n-5.5\n-0.0\n\n\nMO\n24663467\n26117633\n27065546\n-5.6\n-3.5\n\n\nKY\n16910828\n17909495\n18028488\n-5.6\n-0.7\n\n\nLA\n16227594\n17211007\n20262385\n-5.7\n-15.1\n\n\nTX\n66168387\n70514138\n70975901\n-6.2\n-0.7\n\n\nTN\n18102460\n19396554\n18701973\n-6.7\n3.7\n\n\nGA\n26835701\n28816233\n27987249\n-6.9\n3.0\n\n\nAR\n9551686\n10358181\n10596035\n-7.8\n-2.2\n\n\nGU\n75119\n81572\n71813\n-7.9\n13.6\n\n\nMS\n7602710\n8581994\n8915406\n-11.4\n-3.7\n\n\nHI\n3456131\n4135229\n4490320\n-16.4\n-7.9\n\n\nAS\n48828\n67848\n63166\n-28.0\n7.4"
  },
  {
    "objectID": "week02-library.html#filtering-groups-with-having",
    "href": "week02-library.html#filtering-groups-with-having",
    "title": "Week 02: Library Survey Tables Case Study",
    "section": "1.4 Filtering Groups with HAVING",
    "text": "1.4 Filtering Groups with HAVING\nThe HAVING clause is used to filter records that work on summarized GROUP BY results. It is similar to the WHERE clause, but it is used for filtering groups instead of individual rows.\nLet‚Äôs try to compare libraries located in a state with similar characteristics. For that, we will use HAVING to place conditions on gorups created by aggregating.\n\n%%sql\nSELECT pls2018.stabr,\nsum(pls2018.visits) AS visits_2018,\nsum(pls2017.visits) AS visits_2017,\nsum(pls2016.visits) AS visits_2016,\nround ( ( \n         (sum(pls2018.visits) - sum(pls2017.visits) ) * 1.0 / sum(pls2017.visits) ) * 100, 1\n       ) AS visits_ratio_2018_2017,\nround ( ( (sum(pls2017.visits) - sum(pls2016.visits) ) * 1.0 / \n         sum(pls2016.visits) ) * 100, 1) AS visits_ratio_2017_2016\nFROM libraries_2018 AS pls2018\n    JOIN libraries_2017 AS pls2017 ON pls2018.fscskey = pls2017.fscskey\n    JOIN libraries_2016 AS pls2016 ON pls2018.fscskey = pls2016.fscskey\nWHERE pls2018.visits &gt;= 0\n  AND pls2017.visits &gt;= 0\n  AND pls2016.visits &gt;= 0\nGROUP BY pls2018.stabr\nHAVING sum(pls2018.visits) &gt; 50000000\nORDER BY visits_ratio_2018_2017 DESC;\n\n * sqlite:///dbs/w02/library.db\nDone.\n\n\n\n\n\nstabr\nvisits_2018\nvisits_2017\nvisits_2016\nvisits_ratio_2018_2017\nvisits_ratio_2017_2016\n\n\n\n\nFL\n68423689\n66697122\n70991029\n2.6\n-6.0\n\n\nNY\n97921323\n100012193\n103081304\n-2.1\n-3.0\n\n\nCA\n146656984\n151056672\n155613529\n-2.9\n-2.9\n\n\nIL\n63466887\n66166082\n67336230\n-4.1\n-1.7\n\n\nOH\n68176967\n71895854\n74119719\n-5.2\n-3.0\n\n\nTX\n66168387\n70514138\n70975901\n-6.2\n-0.7\n\n\n\n\n\n\nWe are including only rows with a sum greater than 50 million visitors in 2018. We got six states as a result of this arbitrary condition. Only Florida experienced an increase in the number of visitors from 2017 to 2018."
  },
  {
    "objectID": "hws/hw01.html",
    "href": "hws/hw01.html",
    "title": "Homework 01: From zero to‚Ä¶",
    "section": "",
    "text": "From zero to hero!\nWelcome to CS354 - Database Management Systems! This is your first homework, and you will be guided through the steps you need to take to complete it."
  },
  {
    "objectID": "hws/hw01.html#objectives",
    "href": "hws/hw01.html#objectives",
    "title": "Homework 01: From zero to‚Ä¶",
    "section": "Objectives:",
    "text": "Objectives:\nIn this exercise, you will:\n\nShow you understand how SELECT queries work for different tables.\nShow you learned how to visualize data by filtering rows and columns according to what is required.\nShow you are able to follow instructions and navigate in a given database."
  },
  {
    "objectID": "hws/hw01.html#to-moodle",
    "href": "hws/hw01.html#to-moodle",
    "title": "Homework 01: From zero to‚Ä¶",
    "section": "To Moodle!",
    "text": "To Moodle!\nYou will log in to Calvin‚Äôs Moodle, enter the course‚Äôs virtual classroom, and find a task named ‚ÄúHomework 1.‚Äù Follow the steps outlined there. Remember that we are using CodeRunner, a Moodle plugin that allows students to execute SQL queries and receive automatic feedback.\nYou may find this first assignment a bit challenging, but I will give you extra time to complete it so that you have enough time to get acquainted with the system."
  },
  {
    "objectID": "hws/hw01.html#grading-rubric",
    "href": "hws/hw01.html#grading-rubric",
    "title": "Homework 01: From zero to‚Ä¶",
    "section": "Grading Rubric",
    "text": "Grading Rubric\n100 pts total."
  },
  {
    "objectID": "hws/hw03.html",
    "href": "hws/hw03.html",
    "title": "Homework 03:",
    "section": "",
    "text": "In this exercise, you will:"
  },
  {
    "objectID": "hws/hw03.html#objectives",
    "href": "hws/hw03.html#objectives",
    "title": "Homework 03:",
    "section": "",
    "text": "In this exercise, you will:"
  },
  {
    "objectID": "hws/hw03.html#introduction",
    "href": "hws/hw03.html#introduction",
    "title": "Homework 03:",
    "section": "Introduction",
    "text": "Introduction\nBlablabla"
  },
  {
    "objectID": "hws/hw03.html#getting-started",
    "href": "hws/hw03.html#getting-started",
    "title": "Homework 03:",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "hws/hw03.html#submit",
    "href": "hws/hw03.html#submit",
    "title": "Homework 03:",
    "section": "Submit",
    "text": "Submit\nDon‚Äôt forget to commit your changes.\nGrading Rubric: XX points total"
  },
  {
    "objectID": "hws/hw06.html",
    "href": "hws/hw06.html",
    "title": "Homework 06:",
    "section": "",
    "text": "Equality."
  },
  {
    "objectID": "hws/hw06.html#objectives",
    "href": "hws/hw06.html#objectives",
    "title": "Homework 06:",
    "section": "Objectives:",
    "text": "Objectives:\nIn this exercise, you will:\n\nBuild more List operations.\nPractice using pointers."
  },
  {
    "objectID": "hws/hw06.html#introduction",
    "href": "hws/hw06.html#introduction",
    "title": "Homework 06:",
    "section": "Introduction",
    "text": "Introduction\nIn this week‚Äôs lab you will add more functionality to the List class we built in class.\nHere is the invite.\nUse git clone to get your copy of the assignment, as we have been doing. You should have these files: List.cpp, List.h, tests.cpp, plus a makefile, etc.\nIf you are working with a partner, so make sure you join the same Team when creating your repos. Also, put both your names in the README.md file now."
  },
  {
    "objectID": "hws/hw06.html#step-1.-append",
    "href": "hws/hw06.html#step-1.-append",
    "title": "Homework 06:",
    "section": "Step 1. Append",
    "text": "Step 1. Append\nThe append() method is easy to understand: given a new Item, add it to the end of the linked list. The tests.cpp file contains tests already for append().\nNow, implement the code for append(). You might find looking at the implementation of prepend() to be helpful ‚Äì although append() is a bit more complicated. DRAW PICTURES! (Or, don‚Äôt draw pictures, if you want to make this step of the lab take much longer‚Ä¶)"
  },
  {
    "objectID": "hws/hw06.html#step-2.-searching",
    "href": "hws/hw06.html#step-2.-searching",
    "title": "Homework 06:",
    "section": "Step 2. Searching",
    "text": "Step 2. Searching\nLet‚Äôs implement a method that searches the linked list for a given Item, and returns the index of where the item is found, or -1 if it is not found. Name the method getIndexOf(). Here is the prototype:\nint getIndexOf(const Item &it) const;\nFirst implement tests of getIndexOf() in tests.cpp, and then implement the method. You must call the TEST_CASE ‚Äúlookfor‚Äù. I.e., put this in the tests.cpp file:\nTEST_CASE(\"lookfor\") {\n     // add your tests here -- either inside SECTION()s or not.\n}"
  },
  {
    "objectID": "hws/hw06.html#step-3.-copy-constructor",
    "href": "hws/hw06.html#step-3.-copy-constructor",
    "title": "Homework 06:",
    "section": "Step 3. Copy constructor",
    "text": "Step 3. Copy constructor\nYou knew it was coming‚Ä¶\ntests.cpp does not contain any test cases for this, so you‚Äôll have to implement them yourself. My solution has 1 TEST_CASE with 3 SECTIONS: copying a 0-element List, copying a 1-element List, and copying a \\(&gt;1\\)-element list. The name of the TEST_CASE must be copy constructor:\nTEST_CASE(\"copy\") {\n     // add your tests here -- either inside SECTION()s or not.\n}\nThe prototype of the copy constructor will be:\nList(const List & original);\nHere is the algorithm to implement the copy constructor:\n\nSet all the instance variables (myFirst, myLast, mySize) to default values.\nWalk the list of nodes in original, calling append() on the value in each node. (You are calling append() on ‚Äúthis‚Äù node, thus adding a new node each time to the List being constructed.)"
  },
  {
    "objectID": "hws/hw06.html#step-4.-equality",
    "href": "hws/hw06.html#step-4.-equality",
    "title": "Homework 06:",
    "section": "Step 4. Equality",
    "text": "Step 4. Equality\nImplement the equality method, so that you can test if two List objects have the same number of nodes and the items in the nodes are the same. The equality operator returns true or false.\nE.g.,\nif list1 contains 3 values: 11, 22, 33 and list2 contains four values: 11, 22, 33, 44, then list1 == list2 should return false.\nTo test this you have to use == (not !=), so your test might look like this:\nREQUIRE(! (list1 == list2) );\nCreate your tests first in a test case called ‚Äúequality‚Äù:\nTEST_CASE(\"equality\") {\n     // add your tests here -- either inside SECTION()s or not.\n}\n\n\n\n\n\n\nTip\n\n\n\nUse a ‚Äúcurr‚Äù pointer to each list‚Äôs myFirst node, then in a loop, check if the items are the same for the two nodes, then move each curr pointer to its next node."
  },
  {
    "objectID": "hws/hw06.html#step-5.-templatize",
    "href": "hws/hw06.html#step-5.-templatize",
    "title": "Homework 06:",
    "section": "Step 5. Templatize",
    "text": "Step 5. Templatize\nNow, convert your List class to a List&lt;Item&gt; template and modify the tests in tests.cpp to test your new template. Remember to edit the makefile to remove List.cpp from the SOURCES line near the top of the file. You should also delete the List.cpp file completely from your tree."
  },
  {
    "objectID": "hws/hw06.html#submit",
    "href": "hws/hw06.html#submit",
    "title": "Homework 06:",
    "section": "Submit",
    "text": "Submit\nA part of your grade will be based on the thoroughness of your tests; you may want to model your tests after those provided for you in previous projects.\nDon‚Äôt forget to Commit and Push your changes to your repo.\nVerify you have synced your code to github by going to your online repo webpage and looking to see that the files are correct.\nVerify that the autograding tests have passed in github.com."
  },
  {
    "objectID": "hws/hw06.html#grading-rubric",
    "href": "hws/hw06.html#grading-rubric",
    "title": "Homework 06:",
    "section": "Grading Rubric:",
    "text": "Grading Rubric:\nYou will be graded this way: 19 pts total\n\n4 pts each for append(), getIndexOf(), copy constructor, and equality operator (16 pts)\n3 pts for correctness,\n1 pt for thorough tests (you get this point free for append() for which I‚Äôve provided tests).\n3 pts for correctly converting to a class template.\n\nWays students lost points in the past:\n\n-3: Incorrect class template conversion, code does not compile;\n-3: Missing tests for getIndexOf(), copy constructor, and equality operator\n-1: Incomplete equality tests, no tests for when equality is true\n-1: Append implementation needs to adjust the myNext of the current last element\n-1: Copy constructor: myFirst is not initialized to nullptr, causing tests to fail;\n-1: Missing test for equality operator;\n-1: Incomplete test for copy constructor;"
  },
  {
    "objectID": "week02-notes.html",
    "href": "week02-notes.html",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nPerform data aggregation using GROUP BY and HAVING.\nWrite and execute INNER, LEFT-OUTER, RIGHT, and FULL JOINs.\nConstruct subqueries for complex queries.\nImplement SQL functions and expressions.\nUse SQL best practices for readable and efficient queries.\n\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/library.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'"
  },
  {
    "objectID": "week02-notes.html#slos-for-week-02",
    "href": "week02-notes.html#slos-for-week-02",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nPerform data aggregation using GROUP BY and HAVING.\nWrite and execute INNER, LEFT-OUTER, RIGHT, and FULL JOINs.\nConstruct subqueries for complex queries.\nImplement SQL functions and expressions.\nUse SQL best practices for readable and efficient queries.\n\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/library.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'"
  },
  {
    "objectID": "week02-notes.html#sql-aggregation-grouping-with-sqlite-notes",
    "href": "week02-notes.html#sql-aggregation-grouping-with-sqlite-notes",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "üßÆ 1. SQL Aggregation & Grouping (with SQLite Notes)",
    "text": "üßÆ 1. SQL Aggregation & Grouping (with SQLite Notes)\nSQL lets you summarize data using aggregate functions, and group it with GROUP BY. This is especially helpful for statistics, reports, and dashboards.\n\nüéØ Common Aggregate Functions\n\n\n\nFunction\nDescription\nExample\n\n\n\n\nCOUNT()\nNumber of rows\nCOUNT(*)\n\n\nSUM()\nTotal of values\nSUM(amount)\n\n\nAVG()\nMean average\nAVG(score)\n\n\nMIN()\nSmallest value\nMIN(age)\n\n\nMAX()\nLargest value\nMAX(salary)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n‚úÖ SQLite supports all these functions.\n\n\n\n\nüß© Basic Grouping Example\nQ: How many students are in each major?\nSELECT major, COUNT(*) AS student_count\nFROM students\nGROUP BY major;\n\n\n\n\n\n\nNote\n\n\n\n‚úÖ SQLite allows this even if you‚Äôre selecting columns not in the GROUP BY clause or not inside an aggregate function. It will return one arbitrary value from each group for such columns.\n\n\nExample (SQLite accepts this):\nSELECT major, name\nFROM students\nGROUP BY major;\n\n\n\n\n\n\nNote\n\n\n\nThis works in SQLite ‚Äî it will return one name for each major, but which name is returned is undefined. ‚ùå PostgreSQL (and other standards-compliant SQL engines) will reject this query with an error unless name is also in the GROUP BY or wrapped in an aggregate like MIN(name).\n\n\n\n\nüîç Filtering Groups with HAVING\nUse HAVING to filter after grouping.\nQ: Show only majors with more than 10 students:\nSELECT major, COUNT(*) AS student_count\nFROM students\nGROUP BY major\nHAVING COUNT(*) &gt; 10;\n\n\n\n\n\n\nNote\n\n\n\n‚ÑπÔ∏è In SQLite, you can refer to the alias (student_count) in HAVING. In PostgreSQL, you‚Äôd need to repeat the expression: HAVING COUNT(*) &gt; 10.\n\n\n\n\nüìä Combining Aggregates\nQ: Show average GPA per department ‚Äî only if it‚Äôs above 3.5:\nSELECT department, AVG(gpa) AS avg_gpa\nFROM students\nGROUP BY department\nHAVING AVG(gpa) &gt; 3.5;\n\n\nüîó Grouping by Expressions\nYou can group by computed values like substrings or date parts.\nQ: Count students by admission year (from text-based dates):\nSELECT SUBSTR(admission_date, 1, 4) AS year, COUNT(*) AS num_students\nFROM students\nGROUP BY year;\nThe SUBSTR() function extracts a substring from a given string.\nSUBSTR(string, start, length)\n\nstring: the text to extract from\nstart: the position to start (1-based index)\nlength (optional): how many characters to return\n\n-- Get the first 4 characters of a date\nSELECT SUBSTR('2024-09-15', 1, 4);  -- Returns '2024'\n\n-- Get the first letter of a name\nSELECT SUBSTR(name, 1, 1) FROM students;\nüìå If length is omitted, SQLite returns the rest of the string from start.\n\n\n\n\n\n\nNote\n\n\n\n‚úÖ Works well in SQLite (which stores dates as text: YYYY-MM-DD). ‚ùó In PostgreSQL, use: EXTRACT(YEAR FROM admission_date).\n\n\n\n\nüß† Tips for Grouping Queries\n\nUse GROUP BY with aggregate functions.\nUse HAVING to filter groups (not rows).\nUse WHERE for filtering before grouping.\nPrefer column names or expressions in GROUP BY, not just positions (e.g., avoid GROUP BY 1).\nBe cautious using non-aggregated, non-grouped columns in SQLite ‚Äî it‚Äôs allowed, but not portable or predictable."
  },
  {
    "objectID": "week03-06-optimization.html",
    "href": "week03-06-optimization.html",
    "title": "Week 03: SLO 06 ‚Äì Optimize SQL Queries for Better Performance",
    "section": "",
    "text": "Well-optimized SQL queries:\n\nRun faster\nReduce memory and CPU usage\nImprove scalability for large datasets\n\nEven in SQLite, which is lightweight and file-based, writing efficient queries is essential, especially when working with large tables or complex joins."
  },
  {
    "objectID": "week03-06-optimization.html#why-it-matters",
    "href": "week03-06-optimization.html#why-it-matters",
    "title": "Week 03: SLO 06 ‚Äì Optimize SQL Queries for Better Performance",
    "section": "",
    "text": "Well-optimized SQL queries:\n\nRun faster\nReduce memory and CPU usage\nImprove scalability for large datasets\n\nEven in SQLite, which is lightweight and file-based, writing efficient queries is essential, especially when working with large tables or complex joins."
  },
  {
    "objectID": "week03-06-optimization.html#key-techniques-examples",
    "href": "week03-06-optimization.html#key-techniques-examples",
    "title": "Week 03: SLO 06 ‚Äì Optimize SQL Queries for Better Performance",
    "section": "üîß Key Techniques & Examples",
    "text": "üîß Key Techniques & Examples\n\n1. Use SELECT Only What You Need\nAvoid SELECT * ‚Äî only select necessary columns.\n-- Bad\nSELECT * FROM orders;\n\n-- Good\nSELECT order_id, order_date FROM orders;\nüîç In other DBMSs, SELECT * can even prevent index-only scans (e.g., PostgreSQL). In DBMSs like PostgreSQL, an index-only scan is a powerful optimization. It allows the database to read data directly from the index without having to access the full table (also called the heap). This is much faster, especially on large tables.\nBut for this to work, two things must be true:\n\nAll the required columns must be in the index\nThere must be no need to access the actual table rows\n\nSQLite does not support index-only scans in the same way PostgreSQL does. So in SQLite, this specific optimization doesn‚Äôt apply ‚Äî but it‚Äôs still a good habit to avoid SELECT * for performance and clarity.\n\n\n2. Filter Early with WHERE\nApply WHERE clauses to reduce the number of rows processed.\n-- Bad\nSELECT customer_id FROM orders;\n\n-- Good\nSELECT customer_id FROM orders WHERE order_date &gt; '2024-01-01';\nIn SQLite, filtering helps avoid unnecessary disk reads since it uses B-Trees for indexes.\n\n\n3. Use Indexes Wisely\nIndexes speed up WHERE, JOIN, and ORDER BY. But avoid over-indexing!\n-- Create index on order_date for filtering\nCREATE INDEX idx_orders_order_date ON orders(order_date);\nIn PostgreSQL, you can use EXPLAIN to see if indexes are used. In SQLite, use EXPLAIN QUERY PLAN.\nAn index is like a sorted list that a database uses to quickly find data in a table ‚Äî similar to an index in a book.\nInstead of scanning every row (called a full table scan), the database looks in the index to jump directly to the relevant rows, which is much faster.\nüìå Key Points about Indexes\n\nSpeeds up WHERE, JOIN, and ORDER BY queries.\nUses extra disk space.\nToo many indexes = slower inserts/updates (because all indexes need updating).\nBest used on columns frequently used in filtering or joining.\n\n\n\n4. Avoid Functions on Indexed Columns\nUsing functions on columns disables index use.\n-- Bad (no index use)\nSELECT * FROM orders WHERE strftime('%Y', order_date) = '2024';\n\n-- Good\nSELECT * FROM orders WHERE order_date &gt;= '2024-01-01' AND order_date &lt; '2025-01-01';\n\n\n5. Use EXISTS Instead of IN for Subqueries\n-- Slower for large subqueries\nSELECT name FROM customers \nWHERE customer_id IN (SELECT customer_id FROM orders);\n\n-- Faster with EXISTS\nSELECT name FROM customers c\nWHERE EXISTS (\n  SELECT 1 FROM orders o WHERE o.customer_id = c.customer_id\n);\nThis query retrieves the names of customers who have at least one order.\nIn SQLite, both are often converted internally, but EXISTS is still preferable with correlated subqueries.\nThe subquery\nSELECT 1 FROM orders o WHERE o.customer_id = c.customer_id\nsays: ‚ÄúIs there at least one order where orders.customer_id = this customer‚Äôs ID?‚Äù. If yes, the customer is included in the result.\n\n\n\n\n\n\nImportant\n\n\n\nSELECT 1 just returns a dummy value ‚Äî it could be SELECT * or SELECT 'x'; it doesn‚Äôt matter because EXISTS only cares about the existence of at least one matching row.\n\n\nThis is often faster than:\nSELECT name FROM customers\nWHERE customer_id IN (SELECT customer_id FROM orders);\nBecause EXISTS can stop searching early (as soon as it finds a match), while IN may need to collect all values first, depending on the DBMS.\n\n\n6. Use JOINs Instead of Subqueries (when appropriate)\n-- Subquery\nSELECT name FROM customers \nWHERE customer_id IN (\n  SELECT customer_id FROM orders WHERE total &gt; 100\n);\n\n-- JOIN (may perform better)\nSELECT DISTINCT c.name \nFROM customers c\n    JOIN orders o ON c.customer_id = o.customer_id\nWHERE o.total &gt; 100;\nIn MySQL and PostgreSQL, query planners can optimize JOINs more effectively.\n\n\n7. Limit Result Set with LIMIT\nAlways add a LIMIT for preview or pagination.\nSELECT * FROM logs ORDER BY created_at DESC LIMIT 100;"
  },
  {
    "objectID": "week03-06-optimization.html#sqlite-specific-tips",
    "href": "week03-06-optimization.html#sqlite-specific-tips",
    "title": "Week 03: SLO 06 ‚Äì Optimize SQL Queries for Better Performance",
    "section": "üîç SQLite-Specific Tips",
    "text": "üîç SQLite-Specific Tips\n\nA. Use ANALYZE to collect statistics and help the query planner:\nANALYZE;\nANALYZE is a command that collects statistics about the contents of tables and indexes. These statistics help SQLite‚Äôs query planner make better decisions when optimizing queries.\nYou can also analyze a specific table or index:\nANALYZE orders;\nüìà What It Does\n\nStores the data distribution and row counts in a system table called sqlite_stat1.\nHelps SQLite decide:\n\nWhich index to use\nWhether to use an index at all\nThe best join order\n\n\nüìå When to Use\n\nAfter creating new indexes\nAfter loading a large amount of data\nAfter major updates or deletes\n\nIt does not run automatically ‚Äî you should run it manually when needed.\n\n\nB. Use EXPLAIN QUERY PLAN to understand what SQLite is doing:\nEXPLAIN QUERY PLAN SELECT * FROM orders WHERE order_date &gt; '2024-01-01';\nEXPLAIN is a command that shows how SQLite will execute a SQL statement, step by step. It‚Äôs used to understand and debug query performance.\nüîç Two Versions\n\n1. EXPLAIN\nShows low-level virtual machine instructions (for advanced debugging).\nEXPLAIN SELECT * FROM orders;\n\nOutput: Virtual opcodes (not beginner-friendly)\nUse if you‚Äôre deep into SQLite internals\n\n\n\n2. EXPLAIN QUERY PLAN\nThe one you‚Äôll use most. It gives a high-level overview of the query plan.\nEXPLAIN QUERY PLAN \nSELECT * FROM orders WHERE order_date &gt; '2024-01-01';\nTells you:\n\nWhich index (if any) is used\nWhether it does a full table scan\nThe join order\n\nüìå When to Use\n\nTo check if indexes are being used\nTo spot slow queries doing full scans\nBefore/after ANALYZE to see improvements\n\nHere is an example of the output you might see."
  },
  {
    "objectID": "week03-06-optimization.html#comparisons-to-other-dbmss",
    "href": "week03-06-optimization.html#comparisons-to-other-dbmss",
    "title": "Week 03: SLO 06 ‚Äì Optimize SQL Queries for Better Performance",
    "section": "üÜö Comparisons to Other DBMSs",
    "text": "üÜö Comparisons to Other DBMSs\n\n\n\n\n\n\n\n\n\nOptimization Tip\nSQLite\nPostgreSQL\nMySQL\n\n\n\n\nIndex Support\nB-tree only\nB-tree, GiST, GIN, BRIN\nB-tree, Full-text\n\n\nQuery Plan Tool\nEXPLAIN QUERY PLAN\nEXPLAIN (ANALYZE, BUFFERS)\nEXPLAIN\n\n\nParallel Query Support\n‚ùå No\n‚úÖ Yes\n‚úÖ Limited\n\n\nOptimizer Complexity\nSimple\nAdvanced (cost-based)\nModerate"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to CS 354 - Database Management Systems",
    "section": "",
    "text": "Welcome to Database Management, a hands-on course designed to equip you with the essential skills for designing, querying, and optimizing relational databases. Over the next seven weeks, you‚Äôll dive into SQL, explore database structures, and gain practical experience in managing data efficiently. Whether you‚Äôre new to databases or looking to sharpen your skills, this course will provide a solid foundation for real-world applications.\nGet ready to write queries, design schemas, and discover how databases power modern applications! Looking forward to an exciting and engaging learning journey with you all.\nSee you in class!"
  },
  {
    "objectID": "index.html#student-learning-outcomes",
    "href": "index.html#student-learning-outcomes",
    "title": "Welcome to CS 354 - Database Management Systems",
    "section": "Student Learning Outcomes",
    "text": "Student Learning Outcomes\n\nGeneral Student Learning Outcomes (SLOs) for the Course\nBy the end of this Database Management course, students will be able to:\n\nUnderstand the Role of Databases ‚Äì Explain the importance of database management systems and how they support real-world applications.\n\nWrite and Optimize SQL Queries ‚Äì Construct and execute SQL queries to retrieve, manipulate, and analyze data efficiently.\n\nDesign and Normalize Relational Databases ‚Äì Develop well-structured database schemas using BCNF to ensure data integrity and eliminate redundancy.\n\nImplement Relationships and Constraints ‚Äì Define and enforce primary keys, foreign keys, and other integrity constraints to maintain data consistency.\n\nUse Advanced SQL Features ‚Äì Apply concepts like joins, subqueries, indexing, views (materialized vs.¬†non-materialized), and stored procedures to enhance database functionality.\n\nManage Transactions and Security ‚Äì Demonstrate the ability to handle transactions, prevent SQL injection, and implement security best practices.\n\nPerform Database Maintenance and Optimization ‚Äì Explain and apply indexing, query optimization, and backup/recovery strategies for efficient database management.\n\nDevelop a Complete Database System ‚Äì Design, implement, and present a database project that integrates SQL skills, schema design, and optimization techniques.\n\nThese outcomes ensure that students leave the course with both theoretical knowledge and practical, real-world database management skills."
  },
  {
    "objectID": "index.html#course-organization",
    "href": "index.html#course-organization",
    "title": "Welcome to CS 354 - Database Management Systems",
    "section": "Course Organization",
    "text": "Course Organization\nThe course is organized around these components:\n\nThe lectures that will introduce the topics at the practical and conceptual level through live coding and theory explanation;\nThe homeworks in which students will practice using and building databases; and\nThe projects in which students will develop databases systems for real-world problems.\n\nEach week‚Äôs lectures, homeworks and projects will cover the same concepts, but will do so in different ways."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Welcome to CS 354 - Database Management Systems",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis website is built with Quarto. The original code used to build this website can be found at DS Box. We are very grateful for their work!"
  },
  {
    "objectID": "projects/proj03.html#submission",
    "href": "projects/proj03.html#submission",
    "title": "Project 03: soon‚Ä¶",
    "section": "Submission",
    "text": "Submission\n\nGrading Rubric\nThis project is worth xx pts:"
  },
  {
    "objectID": "projects/proj99-final.html#grading-rubric",
    "href": "projects/proj99-final.html#grading-rubric",
    "title": "Final Project: Soon‚Ä¶",
    "section": "Grading Rubric",
    "text": "Grading Rubric\nTotal: XX pts"
  },
  {
    "objectID": "projects/proj04.html#grading-rubric",
    "href": "projects/proj04.html#grading-rubric",
    "title": "Project 04: Soon‚Ä¶",
    "section": "Grading Rubric",
    "text": "Grading Rubric"
  },
  {
    "objectID": "instructors.html",
    "href": "instructors.html",
    "title": "Instructors",
    "section": "",
    "text": "The instructor for this course is Prof.¬†Eric Ara√∫jo."
  },
  {
    "objectID": "instructors.html#office-hours",
    "href": "instructors.html#office-hours",
    "title": "Instructors",
    "section": "Office Hours",
    "text": "Office Hours\n\nThursdays from 2pm until 4pm.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you can‚Äôt meet in during my office hours, use the link below to find free times in my schedule and send me an email requesting to meet during the selected time.\nProf.¬†Ara√∫jo‚Äôs hours"
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "Course content",
    "section": "",
    "text": "CS 354 ‚Äì Database Management Systems ‚Äì is organized by week, with each week structured as follows:\n\nClassroom sessions are Monday-Wednesday-Friday 2.45PM - 3.50PM at SB 382.\nHomeworks are due Friday 23:59. They will be released every Monday.\nProject submission is due Wednesday at 23:59. They will be released every Wednesday.\nTutoring Assistants are available in SB337 on Mondays and Thursdays, from 7 - 9 pm.\n\nThe SLOs (Student Learning Objectives), labs, and projects for each week are given in the links below. The readings are from Ramez Elmasri, S. B. N. (2016). Fundamentals of Database Systems 7th ed.\n\n\n\nWeek\nTopics\nLaboratories\nProjects\nTests, Video Links, etc.\n\n\n\n\n1  ‚Äî  3/17\nIntroduction to Databases & SQL Basics  Week‚Äôs page\nHomework 1\nProj 1\n\n\n\n2  ‚Äî  3/24\nSQL ‚Äì Intermediate Concepts  Advising days ‚Äì no class 26-27 Week‚Äôs page\nHomework 2\nProj 2\n\n\n\n3  ‚Äî  3/31\nSQL ‚Äì Data Modification & Advanced Queries Week‚Äôs page\nHomework 3\nProj 3\n\n\n\n4  ‚Äî  4/7\nDatabase Design ‚Äì ER Modeling & Schema Refinement Week‚Äôs page\nHomework 4\nProj 4\nTest 1: Weeks 1 - 3, Friday\n\n\n5  ‚Äî  4/14\nAdvanced SQL & Integrity Constraints  Good Friday & Easter Monday ‚Äì no class 18-21  Week‚Äôs page\nNo lab\nNo project\n\n\n\n6  ‚Äî  4/22\nDatabase Management & Optimization Week‚Äôs page\nHomework 6\nNo project\n\n\n\n7  ‚Äî  4/28\nFinal Project and Course Wrap-Up Week‚Äôs page\nHomework 7\nFinal Project\n\n\n\nFinal  ‚Äî  May 3-8\nSearch calvin.edu for ‚ÄúExam Schedule‚Äù to find the time of the exam (and all exams you have, this semester, and all future semesters).\n\n\nFinal Test Cumulative, during exam time (You may take it in either class‚Äôs exam time. Classes met at 2.45pm MWF.)",
    "crumbs": [
      "Content",
      "Course content"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (‚ÄúCreative Commons‚Äù) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an ‚Äúas-is‚Äù basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\n\n__Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\n\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\n\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\n\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "week02-case.html",
    "href": "week02-case.html",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "",
    "text": "The CASE statement in SQL is a way to add conditional logic to your queries ‚Äî it‚Äôs like an IF-THEN-ELSE structure in programming languages."
  },
  {
    "objectID": "week02-case.html#basic-syntax-of-case",
    "href": "week02-case.html#basic-syntax-of-case",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "üìå Basic Syntax of CASE",
    "text": "üìå Basic Syntax of CASE\nCASE\n    WHEN condition1 THEN result1\n    WHEN condition2 THEN result2\n    ...\n    ELSE resultN\nEND\nYou can use it:\n\nIn SELECT to create computed columns.\nIn ORDER BY to sort conditionally.\nIn WHERE (less common, but possible)."
  },
  {
    "objectID": "week02-case.html#example-1-using-case-in-a-select",
    "href": "week02-case.html#example-1-using-case-in-a-select",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "‚úÖ Example 1: Using CASE in a SELECT",
    "text": "‚úÖ Example 1: Using CASE in a SELECT\nSELECT name,\n       age,\n       CASE \n           WHEN age &lt; 18 THEN 'Minor'\n           WHEN age &lt; 65 THEN 'Adult'\n           ELSE 'Senior'\n       END AS age_group\nFROM people;\nThis assigns a label (Minor, Adult, or Senior) based on age."
  },
  {
    "objectID": "week02-case.html#example-2-conditional-aggregation",
    "href": "week02-case.html#example-2-conditional-aggregation",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "‚úÖ Example 2: Conditional Aggregation",
    "text": "‚úÖ Example 2: Conditional Aggregation\nSELECT \n    department,\n    COUNT(*) AS total_employees,\n    SUM(CASE WHEN gender = 'F' THEN 1 ELSE 0 END) AS female_employees\nFROM employees\nGROUP BY department;\nThis counts total and female employees per department."
  },
  {
    "objectID": "week02-case.html#example-3-case-in-order-by",
    "href": "week02-case.html#example-3-case-in-order-by",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "‚úÖ Example 3: CASE in ORDER BY",
    "text": "‚úÖ Example 3: CASE in ORDER BY\nSELECT name, priority\nFROM tasks\nORDER BY \n    CASE priority\n        WHEN 'High' THEN 1\n        WHEN 'Medium' THEN 2\n        ELSE 3\n    END;\nThis sorts tasks by custom priority order."
  },
  {
    "objectID": "week02-case.html#notes",
    "href": "week02-case.html#notes",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "üîé Notes",
    "text": "üîé Notes\n\nYou must include END.\nCASE can be nested.\nThere‚Äôs also a simple form:\n\nCASE expression\n    WHEN value1 THEN result1\n    WHEN value2 THEN result2\n    ELSE resultN\nEND\nIt compares a single expression against multiple values."
  },
  {
    "objectID": "week02-case.html#practice-classify-products-by-price",
    "href": "week02-case.html#practice-classify-products-by-price",
    "title": "Week 02: SQL ‚Äì Using CASE",
    "section": "üß™ Practice: Classify Products by Price",
    "text": "üß™ Practice: Classify Products by Price\n\n‚úÖ Table Setup\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/products.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n\n\n%%sql\nCREATE TABLE products (\n    id INTEGER PRIMARY KEY,\n    name TEXT,\n    price REAL\n);\n\nINSERT INTO products (name, price) VALUES\n('Pencil', 0.99),\n('Notebook', 2.49),\n('Backpack', 29.99),\n('Laptop', 999.99),\n('Water Bottle', 12.50);\n\n * sqlite:///dbs/w02/products.db\nDone.\n5 rows affected.\n\n\n[]\n\n\n\n%%sql\nSELECT * FROM products;\n\n * sqlite:///dbs/w02/products.db\nDone.\n\n\n\n\n\nid\nname\nprice\n\n\n\n\n1\nPencil\n0.99\n\n\n2\nNotebook\n2.49\n\n\n3\nBackpack\n29.99\n\n\n4\nLaptop\n999.99\n\n\n5\nWater Bottle\n12.5\n\n\n\n\n\n\n\n\n‚ùì Question:\nWrite an SQL query to return the name, price, and a new column called price_category that shows:\n\n‚ÄòCheap‚Äô if price is less than 5\n‚ÄòModerate‚Äô if price is between 5 and 100\n‚ÄòExpensive‚Äô if price is greater than 100\n\n\n%%sql\nSELECT \n    name,\n    price,\n    CASE \n        WHEN price &lt; 5 THEN 'Cheap'\n        WHEN price &lt;= 100 THEN 'Moderate'\n        ELSE 'Expensive'\n    END AS price_category\nFROM products;\n\n * sqlite:///dbs/w02/products.db\nDone.\n\n\n\n\n\nname\nprice\nprice_category\n\n\n\n\nPencil\n0.99\nCheap\n\n\nNotebook\n2.49\nCheap\n\n\nBackpack\n29.99\nModerate\n\n\nLaptop\n999.99\nExpensive\n\n\nWater Bottle\n12.5\nModerate"
  },
  {
    "objectID": "week03-02-time.html",
    "href": "week03-02-time.html",
    "title": "Week 02: SQL ‚Äì Dates and Times",
    "section": "",
    "text": "In SQLite, date and time operations are handled using a set of built-in functions that work with text values in ISO-8601 format: ‚ÄòYYYY-MM-DD HH:MM:SS‚Äô. These functions can parse, manipulate, and format date/time values.\nHere‚Äôs a breakdown of how date and time functions and operators work in SQLite:"
  },
  {
    "objectID": "week03-02-time.html#common-date-time-functions",
    "href": "week03-02-time.html#common-date-time-functions",
    "title": "Week 02: SQL ‚Äì Dates and Times",
    "section": "üïí Common Date & Time Functions",
    "text": "üïí Common Date & Time Functions\n\n1. DATE(timestring, modifier1, modifier2, ‚Ä¶)\nReturns the date (no time part).\nSELECT DATE('now'); -- Current date (UTC)\nSELECT DATE('now', 'localtime'); -- Current date (local time)\nSELECT DATE('2025-03-30', '+1 day'); -- Adds 1 day\nSELECT DATE('2025-03-30', '-1 month'); -- Subtracts 1 month\n\n\n2. TIME(timestring, modifier1, modifier2, ‚Ä¶)\nReturns the time (no date part).\nSELECT TIME('now'); -- Current time (UTC)\nSELECT TIME('now', 'localtime'); -- Current time (local)\n\n\n3. DATETIME(timestring, modifier1, modifier2, ‚Ä¶)\nReturns both date and time.\nSELECT DATETIME('now'); -- Current date and time (UTC)\nSELECT DATETIME('now', '+1 hour'); -- Adds one hour\n\n\n4. JULIANDAY(timestring, modifier1, ‚Ä¶)\nReturns the Julian day number, which is a floating point value representing days since noon in Greenwich on November 24, 4714 B.C.\nSELECT JULIANDAY('2025-03-30');\n\n\n5. STRFTIME(format, timestring, modifier1, ‚Ä¶)\nReturns a formatted string using format codes.\nSELECT STRFTIME('%Y-%m-%d', 'now'); -- \"2025-03-30\"\nSELECT STRFTIME('%H:%M:%S', 'now'); -- Time part\nSELECT STRFTIME('%Y', 'now');       -- Year only\nüß© Common format codes:\n\n%Y = year (e.g.¬†2025)\n%m = month (01‚Äì12)\n%d = day (01‚Äì31)\n%H = hour (00‚Äì23)\n%M = minute (00‚Äì59)\n%S = seconds (00‚Äì59)\n\n\n\nüõ†Ô∏è Useful Modifiers\nYou can use one or more modifiers to shift the date/time:\n\n\n\nModifier\nEffect\n\n\n\n\n'localtime'\nConverts to local time\n\n\n'utc'\nConverts to UTC\n\n\n'+NNN days'\nAdds NNN days\n\n\n'-NNN months'\nSubtracts NNN months\n\n\n'start of month'\nSets date to the 1st of the month\n\n\n'weekday N'\nMoves to next weekday (0=Sun‚Ä¶6=Sat)\n\n\n'start of year'\nSets date to January 1st\n\n\n\nSELECT DATE('now', 'start of month', '+1 month', '-1 day');\n-- Last day of current month"
  },
  {
    "objectID": "week03-02-time.html#examples",
    "href": "week03-02-time.html#examples",
    "title": "Week 02: SQL ‚Äì Dates and Times",
    "section": "üîç Examples",
    "text": "üîç Examples\n-- Age from birthday\nSELECT (JULIANDAY('now') - JULIANDAY('1990-05-15')) / 365 AS age;\n\n-- Timestamp 7 days from now\nSELECT DATETIME('now', '+7 days');\n\n-- Current time, formatted\nSELECT STRFTIME('%d-%m-%Y %H:%M', 'now', 'localtime');"
  },
  {
    "objectID": "week03-02-time.html#tip-datetime-values-in-sqlite-are-stored-as-text",
    "href": "week03-02-time.html#tip-datetime-values-in-sqlite-are-stored-as-text",
    "title": "Week 02: SQL ‚Äì Dates and Times",
    "section": "üîó Tip: Date/time values in SQLite are stored as TEXT",
    "text": "üîó Tip: Date/time values in SQLite are stored as TEXT\nSQLite doesn‚Äôt have a dedicated DATE or TIME type. Store your datetime values as ISO strings (YYYY-MM-DD HH:MM:SS) for full compatibility with these functions."
  },
  {
    "objectID": "week03-02-time.html#example-database-appointments",
    "href": "week03-02-time.html#example-database-appointments",
    "title": "Week 02: SQL ‚Äì Dates and Times",
    "section": "üì¶ Example Database: appointments",
    "text": "üì¶ Example Database: appointments\nüß± Table: appointments\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/appointments.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n\n\n%%sql\n\nDROP TABLE IF EXISTS appointments;\n\nCREATE TABLE appointments (\n    id INTEGER PRIMARY KEY,\n    title TEXT NOT NULL,\n    client_name TEXT NOT NULL,\n    scheduled_at TEXT NOT NULL  -- Stored in 'YYYY-MM-DD HH:MM:SS' format\n);\n\n-- Sample data\nINSERT INTO appointments (title, client_name, scheduled_at) VALUES\n('Consultation', 'Alice', '2025-03-30 10:00:00'),\n('Follow-up', 'Bob', '2025-03-31 14:30:00'),\n('Strategy Meeting', 'Charlie', '2025-04-01 09:00:00'),\n('Project Review', 'Diana', '2025-04-01 16:45:00'),\n('Feedback Session', 'Eve', '2025-04-02 11:15:00');\n\n * sqlite:///dbs/w02/appointments.db\nDone.\nDone.\n5 rows affected.\n\n\n[]\n\n\n\nüß™ Example Queries Using Date/Time Functions\n\n‚úÖ 1. Get all appointments today (UTC)\n\n%%sql\nSELECT * \nFROM appointments \nWHERE DATE(scheduled_at) = DATE('now');\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\nid\ntitle\nclient_name\nscheduled_at\n\n\n\n\n2\nFollow-up\nBob\n2025-03-31 14:30:00\n\n\n\n\n\n\n‚úÖ 2. Get all appointments in the next 3 days\n\n%%sql\nSELECT * \nFROM appointments \nWHERE DATE(scheduled_at) BETWEEN DATE('now') AND DATE('now', '+3 days');\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\nid\ntitle\nclient_name\nscheduled_at\n\n\n\n\n2\nFollow-up\nBob\n2025-03-31 14:30:00\n\n\n3\nStrategy Meeting\nCharlie\n2025-04-01 09:00:00\n\n\n4\nProject Review\nDiana\n2025-04-01 16:45:00\n\n\n5\nFeedback Session\nEve\n2025-04-02 11:15:00\n\n\n\n\n\n\n‚úÖ 3. Show appointments with day of the week\n\n%%sql\nSELECT \n    id,\n    title,\n    client_name,\n    scheduled_at,\n    STRFTIME('%w', scheduled_at) AS weekday_num,\n    CASE STRFTIME('%w', scheduled_at)\n        WHEN '0' THEN 'Sunday'\n        WHEN '1' THEN 'Monday'\n        WHEN '2' THEN 'Tuesday'\n        WHEN '3' THEN 'Wednesday'\n        WHEN '4' THEN 'Thursday'\n        WHEN '5' THEN 'Friday'\n        WHEN '6' THEN 'Saturday'\n    END AS weekday\nFROM appointments;\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\nid\ntitle\nclient_name\nscheduled_at\nweekday_num\nweekday\n\n\n\n\n1\nConsultation\nAlice\n2025-03-30 10:00:00\n0\nSunday\n\n\n2\nFollow-up\nBob\n2025-03-31 14:30:00\n1\nMonday\n\n\n3\nStrategy Meeting\nCharlie\n2025-04-01 09:00:00\n2\nTuesday\n\n\n4\nProject Review\nDiana\n2025-04-01 16:45:00\n2\nTuesday\n\n\n5\nFeedback Session\nEve\n2025-04-02 11:15:00\n3\nWednesday\n\n\n\n\n\n\n‚úÖ 4. Count how many appointments per day\n\n%%sql\nSELECT \n    DATE(scheduled_at) AS date,\n    COUNT(*) AS total_appointments\nFROM appointments\nGROUP BY DATE(scheduled_at);\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\ndate\ntotal_appointments\n\n\n\n\n2025-03-30\n1\n\n\n2025-03-31\n1\n\n\n2025-04-01\n2\n\n\n2025-04-02\n1\n\n\n\n\n\n\n‚úÖ 5. Check if any appointment is scheduled on a weekend\n\n%%sql\nSELECT *\nFROM appointments\nWHERE STRFTIME('%w', scheduled_at) IN ('0', '6');  -- Sunday or Saturday\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\nid\ntitle\nclient_name\nscheduled_at\n\n\n\n\n1\nConsultation\nAlice\n2025-03-30 10:00:00\n\n\n\n\n\n\n‚úÖ 6. Show how many hours until each appointment (from now)\n\n%%sql\nSELECT \n    id,\n    title,\n    scheduled_at,\n    ROUND((JULIANDAY(scheduled_at) - JULIANDAY('now')) * 24, 2) AS hours_until\nFROM appointments;\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\nid\ntitle\nscheduled_at\nhours_until\n\n\n\n\n1\nConsultation\n2025-03-30 10:00:00\n-14.31\n\n\n2\nFollow-up\n2025-03-31 14:30:00\n14.19\n\n\n3\nStrategy Meeting\n2025-04-01 09:00:00\n32.69\n\n\n4\nProject Review\n2025-04-01 16:45:00\n40.44\n\n\n5\nFeedback Session\n2025-04-02 11:15:00\n58.94\n\n\n\n\n\n\n\nüåç Example: Show today‚Äôs local appointments\n\n%%sql\nSELECT *\nFROM appointments\nWHERE DATE(scheduled_at) = DATE('now', 'localtime');\n\n * sqlite:///dbs/w02/appointments.db\nDone.\n\n\n\n\n\nid\ntitle\nclient_name\nscheduled_at\n\n\n\n\n1\nConsultation\nAlice\n2025-03-30 10:00:00\n\n\n\n\n\n\nExplanation:\n\nDATE(‚Äònow‚Äô, ‚Äòlocaltime‚Äô) gets today‚Äôs date in the local time zone.\nThis query filters all appointments scheduled for today (local time)."
  },
  {
    "objectID": "week02-04-union.html",
    "href": "week02-04-union.html",
    "title": "Week 02: Union, Union All, Intersect, Except",
    "section": "",
    "text": "Operator\nDescription\nDuplicates\nOrder Requirement\nSupported in SQLite\n\n\n\n\nUNION\nCombines results from two queries, removing duplicates\nNo\nYes (same number and types)\nYes\n\n\nUNION ALL\nCombines results from two queries, keeping duplicates\nYes\nYes\nYes\n\n\nINTERSECT\nReturns rows common to both queries\nNo\nYes\nYes\n\n\nEXCEPT\nReturns rows from the first query that are not in the second\nNo\nYes\nYes\n\n\n\n\n\nQ1: What is the difference between UNION and UNION ALL?\n\nUNION combines results from two queries and removes duplicates.\nUNION ALL combines results from two queries and keeps duplicates.\n\nQ2: What does the INTERSECT operator do?\n\nThe INTERSECT operator returns rows that are common to both queries.\n\nQ3: What does the EXCEPT operator do?\n\nThe EXCEPT operator returns rows from the first query that are not present in the second query.\n\nQ4: Do all set operators require the same number of columns and data types in the queries?\n\nYes, all set operators require the same number of columns and compatible data types in the queries.\n\nQ5: Are set operators supported in SQLite?\n\nYes, all set operators are supported in SQLite.\n\nQ6: Do set operators remove duplicates by default?\n\nYes, UNION and INTERSECT remove duplicates by default, while UNION ALL keeps duplicates.\n\nQ7: Can you use set operators with different data types?\n\nNo, set operators require compatible data types in the queries.\n\nQ8: Do set operators require the same order of columns in the queries?\n\nYes, set operators require the same order of columns in the queries.\n\nQ9: Can you use set operators with subqueries?\n\nYes, you can use set operators with subqueries as long as the subqueries return compatible data types and the same number of columns.\n\nQ10: What happens if the queries in a set operator have different numbers of columns?\n\nIf the queries in a set operator have different numbers of columns, an error will occur.\n\nQ11: Can you use set operators with different table names?\n\nYes, you can use set operators with different table names as long as the queries return compatible data types and the same number of columns.\n\nQ12: Can you use set operators with different column names?\n\nYes, you can use set operators with different column names as long as the queries return compatible data types and the same number of columns.\n\nQ13: Can you use set operators with different data sources?\n\nYes, you can use set operators with different data sources as long as the queries return compatible data types and the same number of columns."
  },
  {
    "objectID": "week02-04-union.html#set-operators-in-sql",
    "href": "week02-04-union.html#set-operators-in-sql",
    "title": "Week 02: Union, Union All, Intersect, Except",
    "section": "",
    "text": "Operator\nDescription\nDuplicates\nOrder Requirement\nSupported in SQLite\n\n\n\n\nUNION\nCombines results from two queries, removing duplicates\nNo\nYes (same number and types)\nYes\n\n\nUNION ALL\nCombines results from two queries, keeping duplicates\nYes\nYes\nYes\n\n\nINTERSECT\nReturns rows common to both queries\nNo\nYes\nYes\n\n\nEXCEPT\nReturns rows from the first query that are not in the second\nNo\nYes\nYes\n\n\n\n\n\nQ1: What is the difference between UNION and UNION ALL?\n\nUNION combines results from two queries and removes duplicates.\nUNION ALL combines results from two queries and keeps duplicates.\n\nQ2: What does the INTERSECT operator do?\n\nThe INTERSECT operator returns rows that are common to both queries.\n\nQ3: What does the EXCEPT operator do?\n\nThe EXCEPT operator returns rows from the first query that are not present in the second query.\n\nQ4: Do all set operators require the same number of columns and data types in the queries?\n\nYes, all set operators require the same number of columns and compatible data types in the queries.\n\nQ5: Are set operators supported in SQLite?\n\nYes, all set operators are supported in SQLite.\n\nQ6: Do set operators remove duplicates by default?\n\nYes, UNION and INTERSECT remove duplicates by default, while UNION ALL keeps duplicates.\n\nQ7: Can you use set operators with different data types?\n\nNo, set operators require compatible data types in the queries.\n\nQ8: Do set operators require the same order of columns in the queries?\n\nYes, set operators require the same order of columns in the queries.\n\nQ9: Can you use set operators with subqueries?\n\nYes, you can use set operators with subqueries as long as the subqueries return compatible data types and the same number of columns.\n\nQ10: What happens if the queries in a set operator have different numbers of columns?\n\nIf the queries in a set operator have different numbers of columns, an error will occur.\n\nQ11: Can you use set operators with different table names?\n\nYes, you can use set operators with different table names as long as the queries return compatible data types and the same number of columns.\n\nQ12: Can you use set operators with different column names?\n\nYes, you can use set operators with different column names as long as the queries return compatible data types and the same number of columns.\n\nQ13: Can you use set operators with different data sources?\n\nYes, you can use set operators with different data sources as long as the queries return compatible data types and the same number of columns."
  },
  {
    "objectID": "week02-04-union.html#queries-references",
    "href": "week02-04-union.html#queries-references",
    "title": "Week 02: Union, Union All, Intersect, Except",
    "section": "üë©üèΩ‚Äçüíª Queries References",
    "text": "üë©üèΩ‚Äçüíª Queries References\n-- Example of UNION\nSELECT column1, column2 FROM table1\nUNION\nSELECT column1, column2 FROM table2;\n-- Example of UNION ALL\nSELECT column1, column2 FROM table1\nUNION ALL\nSELECT column1, column2 FROM table2;\n-- Example of INTERSECT\nSELECT column1, column2 FROM table1\nINTERSECT\nSELECT column1, column2 FROM table2;\n-- Example of EXCEPT\nSELECT column1, column2 FROM table1\nEXCEPT\nSELECT column1, column2 FROM table2;"
  },
  {
    "objectID": "week02-04-union.html#scenario-premier-league-vs-champions-league",
    "href": "week02-04-union.html#scenario-premier-league-vs-champions-league",
    "title": "Week 02: Union, Union All, Intersect, Except",
    "section": "‚öΩ Scenario: Premier League vs Champions League",
    "text": "‚öΩ Scenario: Premier League vs Champions League\nWe‚Äôll create two tables:\n\npremier_league_teams: current Premier League teams.\nchampions_league_teams: clubs currently in the UEFA Champions League.\n\nSome Premier League teams also play in the Champions League, but not all Champions League teams are English."
  },
  {
    "objectID": "week02-04-union.html#table-definitions-and-sample-data",
    "href": "week02-04-union.html#table-definitions-and-sample-data",
    "title": "Week 02: Union, Union All, Intersect, Except",
    "section": "üß± Table Definitions and Sample Data",
    "text": "üß± Table Definitions and Sample Data\n\n%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/slo2.4-union.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n\n\n%%sql\n\nDROP TABLE IF EXISTS premier_league_teams;\nDROP TABLE IF EXISTS champions_league_teams;\n\nCREATE TABLE premier_league_teams (\n    team_name TEXT,\n    jersey_color TEXT,\n    founded_year INTEGER,\n    city TEXT\n);\n\nCREATE TABLE champions_league_teams (\n    team_name TEXT,\n    jersey_color TEXT,\n    founded_year INTEGER,\n    city TEXT\n);\n\n * sqlite:///dbs/w02/slo2.4-union.db\nDone.\nDone.\nDone.\nDone.\n\n\n[]"
  },
  {
    "objectID": "week02-04-union.html#sample-inserts",
    "href": "week02-04-union.html#sample-inserts",
    "title": "Week 02: Union, Union All, Intersect, Except",
    "section": "‚öΩ Sample Inserts",
    "text": "‚öΩ Sample Inserts\n\n%%sql\nINSERT INTO premier_league_teams VALUES\n('Manchester City', 'Sky Blue', 1880, 'Manchester'),\n('Arsenal', 'Red and White', 1886, 'London'),\n('Liverpool', 'Red', 1892, 'Liverpool'),\n('Chelsea', 'Blue', 1905, 'London'),\n('Manchester United', 'Red', 1878, 'Manchester'),\n('Tottenham', 'White and Navy', 1882, 'London');\n\nINSERT INTO champions_league_teams VALUES\n('Real Madrid', 'White', 1902, 'Madrid'),\n('Barcelona', 'Blue and Red', 1899, 'Barcelona'),\n('Manchester City', 'Sky Blue', 1880, 'Manchester'),\n('Bayern Munich', 'Red and White', 1900, 'Munich'),\n('Paris Saint-Germain', 'Blue and Red', 1970, 'Paris'),\n('Arsenal', 'Red and White', 1886, 'London'),\n('Inter Milan', 'Blue and Black', 1908, 'Milan'),\n('Liverpool', 'Red', 1892, 'Liverpool'),\n('Liverpool', 'Red', 1892, 'Liverpool'); -- duplicate\n\n * sqlite:///dbs/w02/slo2.4-union.db\n6 rows affected.\n9 rows affected.\n\n\n[]\n\n\n\nüîç Updated Query Examples with All Columns\n1. UNION: All distinct teams with full details\nSELECT * FROM premier_league_teams\nUNION\nSELECT * FROM champions_league_teams;\n\n%%sql\nSELECT * FROM premier_league_teams\nUNION\nSELECT * FROM champions_league_teams;\n\n * sqlite:///dbs/w02/slo2.4-union.db\nDone.\n\n\n\n\n\nteam_name\njersey_color\nfounded_year\ncity\n\n\n\n\nArsenal\nRed and White\n1886\nLondon\n\n\nBarcelona\nBlue and Red\n1899\nBarcelona\n\n\nBayern Munich\nRed and White\n1900\nMunich\n\n\nChelsea\nBlue\n1905\nLondon\n\n\nInter Milan\nBlue and Black\n1908\nMilan\n\n\nLiverpool\nRed\n1892\nLiverpool\n\n\nManchester City\nSky Blue\n1880\nManchester\n\n\nManchester United\nRed\n1878\nManchester\n\n\nParis Saint-Germain\nBlue and Red\n1970\nParis\n\n\nReal Madrid\nWhite\n1902\nMadrid\n\n\nTottenham\nWhite and Navy\n1882\nLondon\n\n\n\n\n\n2. INTERSECT: Full details of teams in both leagues\nSELECT * FROM premier_league_teams\nINTERSECT\nSELECT * FROM champions_league_teams;\n\n%%sql\nSELECT * FROM premier_league_teams\nINTERSECT\nSELECT * FROM champions_league_teams;\n\n * sqlite:///dbs/w02/slo2.4-union.db\nDone.\n\n\n\n\n\nteam_name\njersey_color\nfounded_year\ncity\n\n\n\n\nArsenal\nRed and White\n1886\nLondon\n\n\nLiverpool\nRed\n1892\nLiverpool\n\n\nManchester City\nSky Blue\n1880\nManchester\n\n\n\n\n\n3. EXCEPT: PL teams not in the CL (full detail)\nSELECT * FROM premier_league_teams\nEXCEPT\nSELECT * FROM champions_league_teams;\n\n%%sql\nSELECT * FROM premier_league_teams\nEXCEPT\nSELECT * FROM champions_league_teams;\n\n * sqlite:///dbs/w02/slo2.4-union.db\nDone.\n\n\n\n\n\nteam_name\njersey_color\nfounded_year\ncity\n\n\n\n\nChelsea\nBlue\n1905\nLondon\n\n\nManchester United\nRed\n1878\nManchester\n\n\nTottenham\nWhite and Navy\n1882\nLondon\n\n\n\n\n\n\nSome things for you to try out:\n\nQuery for oldest teams only in PL using EXCEPT and ORDER BY founded_year\nGroup teams by city and count how many come from each city (with GROUP BY)\nMatch color styles (e.g., WHERE jersey_color LIKE ‚Äò%Red%‚Äô)\nJoin both tables on team_name to compare differences (e.g., color changes)"
  },
  {
    "objectID": "projects/proj01.html",
    "href": "projects/proj01.html",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "",
    "text": "Studoggy.\nThis project will introduce you to database creation, table design, and basic SQL queries using SQLite3 and SQLiteStudio. You will create a simple database to store student and course information, learning how to define tables, insert data, and retrieve information using SQL."
  },
  {
    "objectID": "projects/proj01.html#objectives",
    "href": "projects/proj01.html#objectives",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Objectives:",
    "text": "Objectives:\nBy the end of this project, you will:\n‚úÖ Understand how to create and structure a relational database using SQLite3.\n‚úÖ Learn to define tables, primary keys, and foreign keys.\n‚úÖ Insert data into tables and retrieve information using SELECT queries.\n‚úÖ Use basic SQL commands such as CREATE TABLE, INSERT, SELECT, WHERE, and JOIN.\n‚úÖ Gain hands-on experience with SQLiteStudio as a database management tool."
  },
  {
    "objectID": "projects/proj01.html#external-resources",
    "href": "projects/proj01.html#external-resources",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "External resources",
    "text": "External resources\n\nSQL Tutorial\nSQLite Documentation"
  },
  {
    "objectID": "projects/proj01.html#step-0-setting-up-sqlitestudio",
    "href": "projects/proj01.html#step-0-setting-up-sqlitestudio",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Step 0: Setting Up SQLiteStudio",
    "text": "Step 0: Setting Up SQLiteStudio\nBefore you start, ensure that you have SQLiteStudio installed. Follow these steps:\n\nDownload SQLiteStudio from sqlitestudio.pl.\nInstall SQLiteStudio on your computer.\nOpen SQLiteStudio and click on Database -&gt; Add a Database.\nChoose ‚ÄúCreate a new SQLite3 database‚Äù, and name the database university.db after clicking in the yellow folder button.\nClick Save and ensure the database appears in the left panel."
  },
  {
    "objectID": "projects/proj01.html#step-1.-creating-tables",
    "href": "projects/proj01.html#step-1.-creating-tables",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Step 1. Creating Tables",
    "text": "Step 1. Creating Tables\nNow, you will define three tables: students, courses, and enrollments.\n\nTask: Create the students Table\nThis table stores information about students.\n\nOpen SQLiteStudio and select Tools -&gt; Open SQL Editor.\nType the following SQL code:\n\nCREATE TABLE students (\n    student_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    first_name TEXT NOT NULL,\n    last_name TEXT NOT NULL,\n    birthdate DATE,\n    major TEXT\n);\n\nClick Execute (the green play button).\nVerify the table was created by clicking on Database ‚Üí Refresh Structure.\n\n\n\nTask: Create the courses Table\nThis table stores information about courses offered by the university.\n\nIn the SQL Editor, enter the following code:\n\nCREATE TABLE courses (\n    course_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    course_name TEXT NOT NULL,\n    department TEXT NOT NULL\n);\n\nClick Execute and refresh the database structure."
  },
  {
    "objectID": "projects/proj01.html#task-create-the-enrollments-table",
    "href": "projects/proj01.html#task-create-the-enrollments-table",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Task: Create the enrollments Table",
    "text": "Task: Create the enrollments Table\nThis table tracks which students are enrolled in which courses. It includes foreign keys linking to both the students and courses tables.\n\nEnter the following SQL code:\n\nCREATE TABLE enrollments (\n    enrollment_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    student_id INTEGER,\n    course_id INTEGER,\n    enrollment_date DATE DEFAULT CURRENT_DATE,\n    FOREIGN KEY (student_id) REFERENCES students(student_id),\n    FOREIGN KEY (course_id) REFERENCES courses(course_id)\n);\n\nClick Execute and refresh the database structure.\n\n\n\n\n\n\n\nWarning\n\n\n\nCheckpoint: Your database now contains three tables: students, courses, and enrollments."
  },
  {
    "objectID": "projects/proj01.html#step-2.-inserting-data-into-tables",
    "href": "projects/proj01.html#step-2.-inserting-data-into-tables",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Step 2. Inserting Data into Tables",
    "text": "Step 2. Inserting Data into Tables\nNext, you will add sample data to test your database.\n\nTask: Insert Students\n\nType and execute the following SQL commands to insert students:\n\nINSERT INTO students (first_name, last_name, birthdate, major) VALUES\n('Alice', 'Johnson', '2002-05-14', 'Computer Science'),\n('Bob', 'Smith', '2001-09-20', 'Data Science'),\n('Charlie', 'Davis', '2003-01-10', 'Business');\n\n\n\n\n\n\nWarning\n\n\n\nCheckpoint: Click on students table ‚Üí View Data to confirm the data was inserted.\n\n\n\n\nTask: Insert Courses\nNow, insert some courses:\nINSERT INTO courses (course_name, department) VALUES\n('Database Management', 'Computer Science'),\n('Machine Learning', 'Data Science'),\n('Marketing Strategies', 'Business');\n\n\n\n\n\n\nWarning\n\n\n\nCheckpoint: Verify the courses table contains the inserted records.\n\n\n\n\nTask: Enroll Students in Courses\nFinally, insert sample enrollments:\nINSERT INTO enrollments (student_id, course_id) VALUES\n(1, 1),\n(2, 1),\n(2, 2),\n(3, 3);\n\n\n\n\n\n\nWarning\n\n\n\nCheckpoint: Verify the enrollments table now contains data linking students to courses."
  },
  {
    "objectID": "projects/proj01.html#step-3.-writing-and-running-sql-queries",
    "href": "projects/proj01.html#step-3.-writing-and-running-sql-queries",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Step 3. Writing and Running SQL Queries",
    "text": "Step 3. Writing and Running SQL Queries\nNow that your database is set up, you will write SQL queries to retrieve information.\n\nTask 1: List All Courses in the Computer Science Department\nWrite a query to retrieve all courses offered in the Computer Science department.\n-- This is a query to retrieve all courses from the Business department\nSELECT * FROM courses WHERE department = 'Business';\n‚úÖ Expected Output: Should return the ‚ÄúDatabase Management‚Äù course.\n\n\nTask 2: Retrieve All Students.\nWrite an SQL query to display all students in the database ordered by their last names.\n-- This a query that returns all the students.\nSELECT * FROM students;\n‚úÖ Expected Output: A list of all students with their student_id, first_name, last_name, birthdate, and major. They should be ordered in ascending order by ther last names.\n\n\nTask 3: Find All Students Enrolled in ‚ÄúDatabase Management‚Äù\nRetrieve the names of all students who are enrolled in the ‚ÄúDatabase Management‚Äù course.\nSELECT s.first_name, s.last_name\nFROM students s\nJOIN enrollments e ON s.student_id = e.student_id\nJOIN courses c ON e.course_id = c.course_id\nWHERE c.course_name = 'Database Management';\n‚úÖ Expected Output:\nAlice Johnson Bob Smith\n\n\nTask 4: Count the Number of Students in Each Course\nWrite a query to count how many students are enrolled in each course.\nSELECT c.course_name, COUNT(e.student_id) AS num_students\nFROM courses c\nLEFT JOIN enrollments e ON c.course_id = e.course_id\nGROUP BY c.course_name;\n‚úÖ Expected Output: A table showing each course name and the number of enrolled students."
  },
  {
    "objectID": "projects/proj01.html#final-deliverables",
    "href": "projects/proj01.html#final-deliverables",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Final Deliverables",
    "text": "Final Deliverables\nBy the end of this project, you should have:\n\nA SQLite3 database (university.db) with three tables:\n\nstudents, courses, and enrollments.\n\nSuccessfully inserted and retrieved data using SQL.\nWritten four SQL queries to extract meaningful information from the database.\nVerified all queries return the expected results on Moodle."
  },
  {
    "objectID": "projects/proj01.html#bonus-challenge-optional",
    "href": "projects/proj01.html#bonus-challenge-optional",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Bonus Challenge (Optional)",
    "text": "Bonus Challenge (Optional)\nModify the database by adding:\n\nA new professors table and linking it to courses.\nAdditional constraints like UNIQUE or CHECK to enforce data integrity."
  },
  {
    "objectID": "projects/proj01.html#grading-rubric",
    "href": "projects/proj01.html#grading-rubric",
    "title": "Week 1 Project: Student Course Registration System",
    "section": "Grading Rubric",
    "text": "Grading Rubric\nThis project is worth 100 pts:\nGrade will be given by the Quiz available on Moodle from Wednesday (3/19) until the following Wednesday (3/26)."
  },
  {
    "objectID": "projects/proj02.html",
    "href": "projects/proj02.html",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "",
    "text": "This project gives students practical experience using aggregate functions, joins, subqueries, SQL expressions, and query optimization in a multi-table database built with SQLite3 and DBeaver.\nStudents will analyze student records, enrollment patterns, and course performance using intermediate SQL features covered in Week 2."
  },
  {
    "objectID": "projects/proj02.html#objective",
    "href": "projects/proj02.html#objective",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "",
    "text": "This project gives students practical experience using aggregate functions, joins, subqueries, SQL expressions, and query optimization in a multi-table database built with SQLite3 and DBeaver.\nStudents will analyze student records, enrollment patterns, and course performance using intermediate SQL features covered in Week 2."
  },
  {
    "objectID": "projects/proj02.html#learning-outcomes",
    "href": "projects/proj02.html#learning-outcomes",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "üß† Learning Outcomes",
    "text": "üß† Learning Outcomes\nBy completing this project, students will: * Gain confidence using JOINs, GROUP BY, and subqueries * Apply functions and expressions in real-world data * Think critically about query design and efficiency * Practice building clean, well-structured SQL statements in DBeaver"
  },
  {
    "objectID": "projects/proj02.html#step-1-creating-the-database",
    "href": "projects/proj02.html#step-1-creating-the-database",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "Step 1: Creating the Database",
    "text": "Step 1: Creating the Database\n\nüóÇÔ∏è Database Schema\nCreate a new database named university.db with the following tables:\nCREATE TABLE students (\n    student_id INTEGER PRIMARY KEY,\n    first_name TEXT NOT NULL,\n    last_name TEXT NOT NULL,\n    major TEXT,\n    gpa REAL\n);\n\nCREATE TABLE courses (\n    course_id INTEGER PRIMARY KEY,\n    course_name TEXT NOT NULL,\n    department TEXT NOT NULL,\n    credits INTEGER\n);\n\nCREATE TABLE enrollments (\n    enrollment_id INTEGER PRIMARY KEY,\n    student_id INTEGER,\n    course_id INTEGER,\n    grade TEXT,\n    FOREIGN KEY (student_id) REFERENCES students(student_id),\n    FOREIGN KEY (course_id) REFERENCES courses(course_id)\n);\n\n\nüì• Sample Data (Insert Statements)\nProvide the following sample data for testing queries:\n-- Students\nINSERT INTO students (first_name, last_name, major, gpa) VALUES\n('Alice', 'Johnson', 'Computer Science', 3.8),\n('Bob', 'Smith', 'Business', 3.1),\n('Charlie', 'Davis', 'Data Science', 3.5),\n('Diana', 'Lee', 'Computer Science', 2.9),\n('Ethan', 'Brown', 'Data Science', 3.7);\n\n-- Courses\nINSERT INTO courses (course_name, department, credits) VALUES\n('Database Management', 'Computer Science', 3),\n('Marketing 101', 'Business', 2),\n('Machine Learning', 'Data Science', 4),\n('Algorithms', 'Computer Science', 3);\n\n-- Enrollments\nINSERT INTO enrollments (student_id, course_id, grade) VALUES\n(1, 1, 'A'),\n(1, 4, 'B'),\n(2, 2, 'B'),\n(3, 1, 'A'),\n(3, 3, 'A'),\n(4, 1, 'C'),\n(4, 4, 'B'),\n(5, 3, 'A');\n\n\n\n\n\n\nYou can also download the sql file containing the setup of the database and open it in your DBeaver.\n\n\n\nüß∞ Quick Setup Instructions for DBeaver\n\nInstall DBeaver (Community Edition) if not already installed.\nLaunch DBeaver and go to File ‚Üí DBeaver ‚Üí New Database Connection.\nSelect SQLite as the database type.\nClick Next, then Create a new database file, and name it university.db.\nAfter connection, right-click on the database and choose SQL Editor ‚Üí New SQL Script to run the setup and queries.\n\n‚è≥ Load the SQL Script\n\nRight-click the new university.db connection in the Database Navigator pane.\nSelect SQL Editor ‚Üí New SQL Script.\nIn the new script tab that appears, click File ‚Üí Open File.\nSelect the provided file: üìÑ week2_project_setup.sql\nMake sure the Active Datasource (on the top of the window) is connected to the database created."
  },
  {
    "objectID": "projects/proj02.html#step-3-student-tasks",
    "href": "projects/proj02.html#step-3-student-tasks",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "Step 3: Student Tasks",
    "text": "Step 3: Student Tasks\nYou must write SQL queries to answer the following questions:\nüîπ Aggregation & Grouping\n\nFind the average GPA per major.\nCount the number of students enrolled in each course.\nList courses where the number of students enrolled is at least 2.\nFind the average number of credits students are enrolled in (per student).\n\nüîπ Joins\n\nShow each student‚Äôs first and last name along with the names of the courses they are enrolled in.\nList all students and the courses they are NOT enrolled in (use LEFT JOIN and NULL filtering).\nShow courses that have not been taken by any students (use LEFT JOIN or NOT IN).\n\nüîπ Subqueries\n\nFind the names of students who have received an ‚ÄòA‚Äô in any course (use IN or EXISTS).\nList students whose GPA is higher than the average GPA of all students.\nRetrieve courses that have more students than the average number of enrollments per course.\n\nüîπ Functions & Expressions\n\nDisplay students‚Äô names in uppercase.\nShow the length of each course name using a string function.\nCalculate and display a weighted GPA score based on credits * GPA for each student (hint: use a JOIN and a mathematical expression).\n\nüîπ Query Optimization (Conceptual)\n\nConceptual question about Joins."
  },
  {
    "objectID": "projects/proj02.html#submit",
    "href": "projects/proj02.html#submit",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "Submit",
    "text": "Submit\nYou will submit your queries on Moodle."
  },
  {
    "objectID": "projects/proj02.html#grading-rubric",
    "href": "projects/proj02.html#grading-rubric",
    "title": "Project 02: Student Performance & Enrollment Analysis (Using DBeaver)",
    "section": "Grading Rubric",
    "text": "Grading Rubric\nThis project is worth 100 pts."
  },
  {
    "objectID": "week02-analyze.html",
    "href": "week02-analyze.html",
    "title": "Week 02: SQL ‚Äì ANALYZE",
    "section": "",
    "text": "%%capture\n%load_ext sql\n%sql sqlite:///dbs/w02/analyze-example.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'"
  },
  {
    "objectID": "week02-analyze.html#create-a-table-and-insert-data",
    "href": "week02-analyze.html#create-a-table-and-insert-data",
    "title": "Week 02: SQL ‚Äì ANALYZE",
    "section": "1. Create a Table and Insert Data",
    "text": "1. Create a Table and Insert Data\n\n%%sql\n\nDROP TABLE IF EXISTS orders;\n\nCREATE TABLE orders (\n  order_id INTEGER PRIMARY KEY,\n  customer_id INTEGER,\n  order_date TEXT,\n  total REAL\n);\n\n-- Insert 10,000 rows\nWITH RECURSIVE cnt(x) AS (\n  SELECT 1\n  UNION ALL\n  SELECT x + 1 FROM cnt WHERE x &lt; 10000\n)\nINSERT INTO orders (customer_id, order_date, total)\nSELECT \n  ABS(RANDOM() % 100), \n  date('2024-01-01', '+' || (RANDOM() % 365) || ' days'), \n  ROUND(RANDOM() % 500, 2)\nFROM cnt;\n\n * sqlite:///dbs/w02/analyze-example.db\nDone.\nDone.\nDone.\n\n\n[]\n\n\nThis generates 10,000 synthetic rows with:\n\ncustomer_id between 0 and 99\norder_date in the year 2024\ntotal up to 500"
  },
  {
    "objectID": "week02-analyze.html#create-an-index",
    "href": "week02-analyze.html#create-an-index",
    "title": "Week 02: SQL ‚Äì ANALYZE",
    "section": "2. Create an Index",
    "text": "2. Create an Index\n\n%%sql\nCREATE INDEX idx_orders_order_date ON orders(order_date);\n\n * sqlite:///dbs/w02/analyze-example.db\nDone.\n\n\n[]"
  },
  {
    "objectID": "week02-analyze.html#run-a-query-and-check-the-plan",
    "href": "week02-analyze.html#run-a-query-and-check-the-plan",
    "title": "Week 02: SQL ‚Äì ANALYZE",
    "section": "3. Run a Query and Check the Plan",
    "text": "3. Run a Query and Check the Plan\n\n%%sql\nEXPLAIN QUERY PLAN\nSELECT * FROM orders WHERE order_date &gt; '2024-06-01';\n\n * sqlite:///dbs/w02/analyze-example.db\nDone.\n\n\n\n\n\nid\nparent\nnotused\ndetail\n\n\n\n\n3\n0\n205\nSEARCH orders USING INDEX idx_orders_order_date (order_date&gt;?)\n\n\n\n\n\nBefore ANALYZE, SQLite might not use the index if it doesn‚Äôt know how selective order_date is.\nIn our case, the query is optimized and using the index. Let‚Äôs see what the output means.\n\n\n\n\n\n\n\nPart\nMeaning\n\n\n\n\nSEARCH orders\nSQLite is accessing the orders table using a search operation.\n\n\nUSING INDEX idx_orders_order_date\nIt is using the idx_orders_order_date index to speed up the lookup.\n\n\n(order_date&gt;?)\nThe filter condition is order_date &gt; ? (where ? is the input value).\n\n\n\nThis shows that SQLite (1) is not scanning the full table and (2) is using the index you created to efficiently jump to rows matching the condition.\nHad the query said something like:\nSCAN TABLE orders\n‚Ä¶that would mean a full table scan ‚Äî which is slower, especially on large datasets."
  },
  {
    "objectID": "week02-analyze.html#run-analyze",
    "href": "week02-analyze.html#run-analyze",
    "title": "Week 02: SQL ‚Äì ANALYZE",
    "section": "4. Run ANALYZE",
    "text": "4. Run ANALYZE\nThis updates the sqlite_stat1 table with stats about the distribution of values in the table/indexes.\n\n%%sql\nANALYZE;\n\n * sqlite:///dbs/w02/analyze-example.db\nDone.\n\n\n[]\n\n\n\n## 5. Run the Same Query Again\n\n\n%%sql\nEXPLAIN QUERY PLAN\nSELECT * FROM orders WHERE order_date &gt; '2024-06-01';\n\n * sqlite:///dbs/w02/analyze-example.db\nDone.\n\n\n\n\n\nid\nparent\nnotused\ndetail\n\n\n\n\n3\n0\n141\nSEARCH orders USING INDEX idx_orders_order_date (order_date&gt;?)\n\n\n\n\n\nAfter ANALYZE, you‚Äôll likely see that the index is now being used, especially if the planner sees it as more efficient."
  },
  {
    "objectID": "policies.html",
    "href": "policies.html",
    "title": "Course Policies",
    "section": "",
    "text": "Your grade in this course will be based on:\n\nWeekly Quizzes: 5%\n\nQuizzes every Friday.\n\nProjects: 20%\nFinal Project: 25%\nHomework: 20%\nTests (2, including the final test during the Exam time): 30%"
  },
  {
    "objectID": "policies.html#grace-days",
    "href": "policies.html#grace-days",
    "title": "Course Policies",
    "section": "Grace Days",
    "text": "Grace Days\nYou have 4 Grace Days available to you during the semester. These grace days may be used to submit an assignment late without penalty. Grace Days Remaining will be seen in the GradeBook in Moodle.\nHere are some circumstances in which you might use grace days:\n\nYou are an athlete and you have a very busy week. Use a few grace days to catch up the next week.\nYou become ill (physically or mentally) and cannot do the work on time.\nYou need to go home for an emergency.\n\nHere is the procedure for using grace days:\n\nDO NOT email me to tell me you are going to use grace days. I don‚Äôt need to know this ‚Äì there is no action I need to take if you tell me this.\nWhen your assignment grade comes back and you have lost points due to lateness, then send an email to ask for the points to be restored and tell me how many grace days you want to use for that."
  },
  {
    "objectID": "policies.html#extenuating-circumstances",
    "href": "policies.html#extenuating-circumstances",
    "title": "Course Policies",
    "section": "Extenuating Circumstances",
    "text": "Extenuating Circumstances\nIf you fall ill (physically or mentally) for an extended period of time, AND you send me documentation from Student Life, Student Health Center, or the Center for Health and Wellness, then, and only then, I will consider allowing you to make up late assignments.\n\n\n\n\n\n\nWarning\n\n\n\nIf you begin to skip class repeatedly due to mental health problems, go to the Center for Health and Wellness! Don‚Äôt delay!"
  },
  {
    "objectID": "policies.html#incompletes",
    "href": "policies.html#incompletes",
    "title": "Course Policies",
    "section": "Incompletes",
    "text": "Incompletes\nAn Incomplete (I) grade will be granted only in unusual circumstances, and only if those circumstances have been verified by the Student Life Office. Procrastination does not qualify as an unusual circumstance.\nNo work will be accepted after the last day of classes."
  },
  {
    "objectID": "policies.html#classroom-policy",
    "href": "policies.html#classroom-policy",
    "title": "Course Policies",
    "section": "Classroom Policy",
    "text": "Classroom Policy\n\n\n\n\n\n\nIMPORTANT!\n\n\n\nNo phones, no laptops, unless we tell you you can.\n\n\nThis is a difficult class, and you don‚Äôt need to be distracted by goofing around on your phone or laptop. And, I don‚Äôt want you to distract others.\nWeekly Quizzes will be administered in the first 5 minutes of class every Friday, on Moodle. Do not show up late to class."
  },
  {
    "objectID": "policies.html#attendance",
    "href": "policies.html#attendance",
    "title": "Course Policies",
    "section": "Attendance",
    "text": "Attendance\nClass attendance is required.\nMissing class due to illness: if you are going to miss class due to (physical or mental) illness, please send me an email before class."
  },
  {
    "objectID": "policies.html#disabilities",
    "href": "policies.html#disabilities",
    "title": "Course Policies",
    "section": "Disabilities",
    "text": "Disabilities\nCalvin University is committed to providing access to all students. If you are a student with a documented disability, please notify a Disability Coordinator in Student Success (located in Hiemenga Hall 227) to discuss necessary accommodations. If you have an accommodation memo, please come talk to me in the first two weeks of class. If you are a student needing reasonable modifications for pregnancy and related conditions, please contact the Title IX Coordinator in Student Life (located in Spoelhof University Center 364)."
  },
  {
    "objectID": "policies.html#statement-of-diversity-and-inclusion",
    "href": "policies.html#statement-of-diversity-and-inclusion",
    "title": "Course Policies",
    "section": "Statement of Diversity and Inclusion",
    "text": "Statement of Diversity and Inclusion\nInside and outside of the classroom, I work to treat every person with equal respect, regardless of racial identity, gender identity, physicality, brain chemistry, nationality, political leanings, and religious background. Whoever you are, you are fearfully and wonderfully made. God delights in diversity and I do, too. We humans need diverse viewpoints because every viewpoint, on its own, has blind spots. That has been proven to be true in technology-related fields, where under-represented minorities are significantly under-represented in the working world. When companies work hard to rectify this, they find their products and services improve. We have found this to be true in Computer Science classrooms as well.\n\n\n\n\n\n\nIMPORTANT!\n\n\n\nIf you or someone else in this class is hurt by something I say or do in class, I would like to know about it so that we can work toward a remedy. This has happened in the past in my classroom ‚Äì usually when I‚Äôm trying to be ‚Äúcool‚Äù or be funny. If this happens this semester, please know that it was unintentional. Because this kind of feedback can be uncomfortable for all involved, I‚Äôll take it however it comes: in public or in private, on the spot or days later, directly from you or indirectly through another student, another professor, or through my department chair Keith VanderLinden (kvlinden@calvin.edu)."
  },
  {
    "objectID": "security.html",
    "href": "security.html",
    "title": "CS 354 ‚Äì Database Management Systems",
    "section": "",
    "text": "üîê Topics for Database Security\nüîí 1. SQL Injection ‚Ä¢ What it is: Attacks where malicious SQL is injected into a query. ‚Ä¢ Why it matters: It‚Äôs one of the most common web security vulnerabilities. ‚Ä¢ Key concepts: ‚Ä¢ Use of parameterized queries / prepared statements ‚Ä¢ Risks of string concatenation ‚Ä¢ Demo: Show how unsafe user input can manipulate a query. ‚Ä¢ ‚úÖ SQLite supports parameter binding via libraries (like Python‚Äôs sqlite3, PHP, etc.)\n‚∏ª\nüë§ 2. Authentication and Access Control\n(More relevant in full-featured DBMSs, but important conceptually) ‚Ä¢ What it is: Managing who can access what in a database. ‚Ä¢ SQLite doesn‚Äôt support users or roles, but you can: ‚Ä¢ Discuss permissions in PostgreSQL/MySQL (e.g., GRANT, REVOKE) ‚Ä¢ Mention OS-level protections in SQLite (file permissions)\n‚∏ª\nüì¶ 3. Data at Rest Protection ‚Ä¢ Encryption: ‚Ä¢ Explain database-level encryption (e.g., SQLCipher for SQLite) ‚Ä¢ Compare with TDE (Transparent Data Encryption) in SQL Server or Oracle ‚Ä¢ File system security: ‚Ä¢ Emphasize securing the .db file from unauthorized users\n‚∏ª\nüîÑ 4. Backups and Integrity ‚Ä¢ Importance of: ‚Ä¢ Secure and consistent backups ‚Ä¢ Validating data integrity after restore ‚Ä¢ Tools: sqlite3 .backup command, VACUUM for cleanup\n‚∏ª\nüßæ 5. Logging & Auditing ‚Ä¢ What to track: queries, access, errors ‚Ä¢ In SQLite: ‚Ä¢ Logging must be implemented at the application layer ‚Ä¢ In PostgreSQL: ‚Ä¢ Native audit/logging tools exist (e.g., pg_stat_activity)\n‚∏ª\nüìã 6. Principle of Least Privilege ‚Ä¢ Always give users the minimum permissions they need ‚Ä¢ Relate this to: ‚Ä¢ Access control in PostgreSQL (REVOKE ALL, then GRANT what‚Äôs needed) ‚Ä¢ App-level SQLite access modes (read-only, read-write)\n‚∏ª\nüß™ 7. Practical Threat Scenarios ‚Ä¢ What happens if‚Ä¶ ‚Ä¢ The database file is leaked? ‚Ä¢ Users can insert raw SQL? ‚Ä¢ No input validation is done? ‚Ä¢ Use small case studies or labs to reinforce concepts\n‚∏ª\n‚öñÔ∏è Optional (Advanced) ‚Ä¢ Hashing and salting passwords (e.g., for login tables) ‚Ä¢ Certificate-based connections (in PostgreSQL/MySQL) ‚Ä¢ Security implications of cloud databases"
  },
  {
    "objectID": "hws/hw04.html#introduction",
    "href": "hws/hw04.html#introduction",
    "title": "Homework 04:",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "hws/hw04.html#turn-in",
    "href": "hws/hw04.html#turn-in",
    "title": "Homework 04:",
    "section": "Turn In",
    "text": "Turn In"
  },
  {
    "objectID": "hws/hw04.html#grading-rubric",
    "href": "hws/hw04.html#grading-rubric",
    "title": "Homework 04:",
    "section": "Grading Rubric",
    "text": "Grading Rubric"
  },
  {
    "objectID": "hws/hw07.html",
    "href": "hws/hw07.html",
    "title": "Homework 07:",
    "section": "",
    "text": "Definition of Grinch."
  },
  {
    "objectID": "hws/hw07.html#learning-objectives",
    "href": "hws/hw07.html#learning-objectives",
    "title": "Homework 07:",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nIn this exercise, you will:\n\nbuild a hash table data structure\nexperiment with hashing algorithms to distribute data across all buckets, as much as possible."
  },
  {
    "objectID": "hws/hw07.html#step-0",
    "href": "hws/hw07.html#step-0",
    "title": "Homework 07:",
    "section": "Step 0",
    "text": "Step 0\nAccept the Assignment.\nOur hash table will be a STL vector of STL sets (in class we used a vector of linked lists). Your code will read a file, dictionary.txt, that contains ‚Äúall‚Äù the words in the English language, and insert each word into the hash table. There are about ~127,000 words in the file, but we will use a fairly small number of buckets, so there will be many collisions.\nThe goal of this exercise is to experiment with hashing algorithms to see if you can find one that distributes items well."
  },
  {
    "objectID": "hws/hw07.html#step-1-build-the-hashtable-data-structure-and-constructor",
    "href": "hws/hw07.html#step-1-build-the-hashtable-data-structure-and-constructor",
    "title": "Homework 07:",
    "section": "Step 1: Build the HashTable data structure and constructor",
    "text": "Step 1: Build the HashTable data structure and constructor\nInspect the code in HashTable.h and HashTable.cpp. There is not much there, but it is a start. Do notice that there is a static constant integer called TABLE_SIZE, initialized to the value 200.\nCreate the hash table data structure in the private: section, calling it myTable. For this project, the table must be a vector of sets of strings (in class we used a vector of lists).\nIn the constructor, initialize myTable to have TABLE_SIZE buckets by calling\nmyTable.resize(TABLE_SIZE);\nAlso, in the constructor initialize mySize to 0.\nCompile your code to make sure what you have written compiles."
  },
  {
    "objectID": "hws/hw07.html#step-2-insert-and-hash",
    "href": "hws/hw07.html#step-2-insert-and-hash",
    "title": "Homework 07:",
    "section": "Step 2: insert() and hash()",
    "text": "Step 2: insert() and hash()\nThe prototypes for insert() and hash() are defined in the .h file. Now, you must implement them in the .cpp file. Use the code we saw in the slides in class for the hash function. The function should add up the first and last characters of the string, modding the result by TABLE_SIZE.\nTry to compile the code using make. It should compile. Fix any issues if your compilation fails."
  },
  {
    "objectID": "hws/hw07.html#step-3-main",
    "href": "hws/hw07.html#step-3-main",
    "title": "Homework 07:",
    "section": "Step 3: main()",
    "text": "Step 3: main()\nNow, create code in main(). Your code should define a HashTable object first.\nThen, open the file dictionary.txt for reading, and read each word from the file, one at a time, inserting each word into the hash table.\nNext, have the code close the file.\nCompile your code."
  },
  {
    "objectID": "hws/hw07.html#step-4-testing",
    "href": "hws/hw07.html#step-4-testing",
    "title": "Homework 07:",
    "section": "Step 4: Testing",
    "text": "Step 4: Testing\nOf course, at this point, we have no idea if the items have been distributed well in the hash table, because we have no way to inspect the hash table contents.\nNotice that there is a method called dumpInfo() defined, but currently the code does nothing. Fill in the code to do the following:\n\nFor each bucket, print how many items are in it.\nCount and print the number of empty buckets.\nCalculate and print the average number of items in non-empty buckets.\n\nHere is a snippet of my output. Make your output look similar:\nnumber of items in bucket 0: 415\nnumber of items in bucket 1: 351\nnumber of items in bucket 2: 307\nnumber of items in bucket 3: 414\nnumber of items in bucket 4: 293\n...\nnumber of items in bucket 197: 560\nnumber of items in bucket 198: 484\nnumber of items in bucket 199: 341\n--------------------------\nTotal number of elements in the hash table: 127141\nNumber of empty buckets: 0\nAverage number of items in non-empty buckets: 635\n\n\n\n\n\n\nNote\n\n\n\nNote: the output above is from after I changed the number of buckets in my data structure, and tweaked the hash algorithm, which you‚Äôll do below.\n\n\nAfter you implement your dumpInfo() method, call it from your main() code."
  },
  {
    "objectID": "hws/hw07.html#step-5-tweak-your-hashing-algorithm-and-table-size",
    "href": "hws/hw07.html#step-5-tweak-your-hashing-algorithm-and-table-size",
    "title": "Homework 07:",
    "section": "Step 5: Tweak Your Hashing Algorithm and Table Size",
    "text": "Step 5: Tweak Your Hashing Algorithm and Table Size\nYou will notice that the basic hashing algorithm (adding up the first and last characters of each string) does a very poor job of distributing strings across all buckets in the hash table. Your goal now is to improve the hashing algorithm to improve the distribution.\nExperiment with different algorithms, but make sure they follow the criteria laid out in class:\n\nO(1)\ndistribute values across all buckets.\ndeterministic.\n\nYou MAY increase the number of buckets, but it must remain at or below 250 total. Do not change how buckets are implemented ‚Äì they should remain sets.\nDo not spend more than 1 hour tweaking your algorithm. Make sure your final code implements your best algorithm.\n\n\n\n\n\n\nImportant\n\n\n\nWrite a comment in your hash() function that describes your algorithm, explaining why you think it works as well as it does."
  },
  {
    "objectID": "hws/hw07.html#step-6-submit",
    "href": "hws/hw07.html#step-6-submit",
    "title": "Homework 07:",
    "section": "Step 6: Submit",
    "text": "Step 6: Submit\nSubmit your code via github, as normal.\n\n\n\n\n\n\nWarning\n\n\n\nIF YOU WORKED WITH A PARTNER, ONLY ONE OF YOU HAS TO SUBMIT, but UPDATE THE README.md to INCLUDE BOTH NAMES."
  },
  {
    "objectID": "hws/hw07.html#grading-rubric",
    "href": "hws/hw07.html#grading-rubric",
    "title": "Homework 07:",
    "section": "Grading Rubric",
    "text": "Grading Rubric\n20 points total:\n\n10 pts: hash table code (not including the hash function) is correct\n5 pts: hash function obeys the criteria laid out in class.\n3 pts: hash function works well (not obviously leaving many buckets empty and have some be very full).\n2 pts: code is clean and hospitable.\n\nWays students lost points in the past:\n\n-2: Hash function does not appear to be evenly distributed but fills lower-numbered buckets way more (~2000 vs ~50)\n-4: Main function does not load words from file or call dumpInfo\n-1: Missing call to dumpInfo in main\n-3: Buckets are not evenly distributed (with many below 50 or above 2000) and some are empty. The smallest buckets are odd-numbered, which indicates a quirk in the algorithm which disfavors that half of the buckets\n-4: Most of the buckets are empty; a hashing algorithm should seek to evenly distribute words into buckets\n-1: Please output all bucket counts per instructions so the distribution can be seen."
  },
  {
    "objectID": "hws/hw02.html",
    "href": "hws/hw02.html",
    "title": "Homework 02: Multiple tables",
    "section": "",
    "text": "It makes more sense now."
  },
  {
    "objectID": "hws/hw02.html#objectives",
    "href": "hws/hw02.html#objectives",
    "title": "Homework 02: Multiple tables",
    "section": "Objectives:",
    "text": "Objectives:\nIn this exercise, you will:\n\nShow you understand how SELECT queries work for different tables.\nShow you learned how to visualize data by filtering rows and columns according to what is required.\nShow you are able to follow instructions and navigate in a given database.\nUse Joins to handle multiple tables."
  },
  {
    "objectID": "hws/hw02.html#to-moodle",
    "href": "hws/hw02.html#to-moodle",
    "title": "Homework 02: Multiple tables",
    "section": "To Moodle!",
    "text": "To Moodle!\nYou will log in to Calvin‚Äôs Moodle, enter the course‚Äôs virtual classroom, and find a task named ‚ÄúHomework 2.‚Äù Follow the steps outlined there. Remember that we are using CodeRunner, a Moodle plugin that allows students to execute SQL queries and receive automatic feedback."
  },
  {
    "objectID": "hws/hw02.html#grading-rubric",
    "href": "hws/hw02.html#grading-rubric",
    "title": "Homework 02: Multiple tables",
    "section": "Grading Rubric",
    "text": "Grading Rubric\n100 pts total."
  },
  {
    "objectID": "week01-summary.html",
    "href": "week01-summary.html",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nExplain the purpose and importance of relational databases.\nDifferentiate between relational databases and other types of data storage.\nWrite basic SQL queries to retrieve data.\nUnderstand SQL syntax and basic commands for querying: SELECT, DISTINCT, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT/OFFSET.\nAnalyze a dataset using simple queries."
  },
  {
    "objectID": "week01-summary.html#slos-for-week-01",
    "href": "week01-summary.html#slos-for-week-01",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nExplain the purpose and importance of relational databases.\nDifferentiate between relational databases and other types of data storage.\nWrite basic SQL queries to retrieve data.\nUnderstand SQL syntax and basic commands for querying: SELECT, DISTINCT, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT/OFFSET.\nAnalyze a dataset using simple queries."
  },
  {
    "objectID": "week01-summary.html#what-is-a-database",
    "href": "week01-summary.html#what-is-a-database",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "üìñ 1. What is a Database?",
    "text": "üìñ 1. What is a Database?\n\nA¬†database¬†is an organized collection of data that can be easily accessed, managed, and updated.\nCommonly used in web apps, finance systems, university systems, and more."
  },
  {
    "objectID": "week01-summary.html#what-is-a-dbms",
    "href": "week01-summary.html#what-is-a-dbms",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "üìÑ 2. What is a DBMS?",
    "text": "üìÑ 2. What is a DBMS?\n\nA¬†Database Management System (DBMS)¬†is software that allows users to interact with databases.\nExamples:¬†SQLite, MySQL, PostgreSQL, SQL Server.\nFunctions: create, update, retrieve, and manage data."
  },
  {
    "objectID": "week01-summary.html#relational-model",
    "href": "week01-summary.html#relational-model",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "üí° 3. Relational Model",
    "text": "üí° 3. Relational Model\n\nData is stored in tables (called relations) made up of rows (records) and columns (attributes).\nSupports primary keys, foreign keys, and constraints.\nEnforces data integrity and relationships between data."
  },
  {
    "objectID": "week01-summary.html#basic-sql-syntax",
    "href": "week01-summary.html#basic-sql-syntax",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "üìÉ 4. Basic SQL Syntax",
    "text": "üìÉ 4. Basic SQL Syntax\n\nSQL =¬†Structured Query Language¬†used to communicate with databases.\nCore command to retrieve data:\n\nSELECT column1, column2 FROM table_name;\n\nUse¬†*¬†to select all columns:\n\nSELECT * FROM students;"
  },
  {
    "objectID": "week01-summary.html#filtering-data-with-where",
    "href": "week01-summary.html#filtering-data-with-where",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "‚ö†Ô∏è 5. Filtering Data with WHERE",
    "text": "‚ö†Ô∏è 5. Filtering Data with WHERE\n\nFilter records using¬†WHERE:\n\nSELECT * FROM students WHERE major = 'Computer Science';\n\nComparison operators:¬†=,¬†&lt;&gt;,¬†&gt;,¬†&lt;,¬†&gt;=,¬†&lt;=\nLogical operators:¬†AND,¬†OR,¬†NOT"
  },
  {
    "objectID": "week01-summary.html#sorting-results-with-order-by",
    "href": "week01-summary.html#sorting-results-with-order-by",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "‚ñ≤ 6. Sorting Results with ORDER BY",
    "text": "‚ñ≤ 6. Sorting Results with ORDER BY\n\nSort results alphabetically or numerically:\n\nSELECT * FROM students ORDER BY last_name ASC;\n\nUse¬†DESC¬†for descending order"
  },
  {
    "objectID": "week01-summary.html#combining-where-and-order-by",
    "href": "week01-summary.html#combining-where-and-order-by",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "üîÑ 7. Combining WHERE and ORDER BY",
    "text": "üîÑ 7. Combining WHERE and ORDER BY\nSELECT * FROM students\nWHERE gpa &gt;= 3.5\nORDER BY last_name ASC;"
  },
  {
    "objectID": "week01-summary.html#tools-and-environment",
    "href": "week01-summary.html#tools-and-environment",
    "title": "Week 01: Introduction to Databases & SQL Basics",
    "section": "üöÄ 8. Tools and Environment",
    "text": "üöÄ 8. Tools and Environment\n\nWe use¬†SQLite3 with DBeaver¬†to write and run SQL queries.\nCreate¬†.db¬†files to store your database.\nUse the¬†SQL Editor¬†to run commands and explore data.\n\n\nüîπ Pro Tip: Practice Makes Progress!\nWrite and test queries regularly to get comfortable with SQL syntax.\n\nStart with SELECT, WHERE, and ORDER BY‚Äîyou‚Äôll use them everywhere!"
  },
  {
    "objectID": "week06.html",
    "href": "week06.html",
    "title": "Week 06: Database Management & Optimization (under construction)",
    "section": "",
    "text": "At the end of this unit, the student will be able to‚Ä¶\n\nSQL implementation in Python.\nDevelop a backup and recovery plan for a database system.\nExplain different techniques for performance tuning.\nUnderstand database partitioning and indexing strategies.\nProfile SQL queries to detect inefficiencies.\nDiscuss database integration with software applications.\nApply database optimization techniques in real-world scenarios.\nDemonstrate SQL injection and discuss prevention strategies.\nAssign user roles and permissions for database security.\nDebug and troubleshoot complex SQL queries.",
    "crumbs": [
      "Content",
      "Week 06: Database Management & Optimization (under construction)"
    ]
  },
  {
    "objectID": "week06.html#slos-for-week-06",
    "href": "week06.html#slos-for-week-06",
    "title": "Week 06: Database Management & Optimization (under construction)",
    "section": "",
    "text": "At the end of this unit, the student will be able to‚Ä¶\n\nSQL implementation in Python.\nDevelop a backup and recovery plan for a database system.\nExplain different techniques for performance tuning.\nUnderstand database partitioning and indexing strategies.\nProfile SQL queries to detect inefficiencies.\nDiscuss database integration with software applications.\nApply database optimization techniques in real-world scenarios.\nDemonstrate SQL injection and discuss prevention strategies.\nAssign user roles and permissions for database security.\nDebug and troubleshoot complex SQL queries.",
    "crumbs": [
      "Content",
      "Week 06: Database Management & Optimization (under construction)"
    ]
  },
  {
    "objectID": "week06.html#slides-videos-and-application-exercises",
    "href": "week06.html#slides-videos-and-application-exercises",
    "title": "Week 06: Database Management & Optimization (under construction)",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 06: Slides\n\nSlides\n\n\nNo readings for Week 6.\n\n\n\n\nHomework 06:\n\nInstructions\n\n\n\n\nProject 06: No project on Week 06",
    "crumbs": [
      "Content",
      "Week 06: Database Management & Optimization (under construction)"
    ]
  },
  {
    "objectID": "week05.html",
    "href": "week05.html",
    "title": "Week 05: Advanced SQL & Integrity Constraints (under construction)",
    "section": "",
    "text": "By the end of this unit, students will be able to‚Ä¶\n\nWrite and execute triggers for database automation using CREATE TRIGGER, BEFORE, AFTER and INSTEAD OF.\nUnderstand that SQLite is a transactional database where all changes and queries are atomic, consistent, isolated, and durable (ACID) and what it means.\nManage transactions using COMMIT and ROLLBACK.\nHow to perform SQL full-text search using MATCH.\nUse SQLite CLI commands, such as .schema, .table, .headers on/off, .mode column.\nNormalize database schemas using BCNF and 4NF.",
    "crumbs": [
      "Content",
      "Week 05: Advanced SQL & Integrity Constraints (under construction)"
    ]
  },
  {
    "objectID": "week05.html#slos-for-week-05",
    "href": "week05.html#slos-for-week-05",
    "title": "Week 05: Advanced SQL & Integrity Constraints (under construction)",
    "section": "",
    "text": "By the end of this unit, students will be able to‚Ä¶\n\nWrite and execute triggers for database automation using CREATE TRIGGER, BEFORE, AFTER and INSTEAD OF.\nUnderstand that SQLite is a transactional database where all changes and queries are atomic, consistent, isolated, and durable (ACID) and what it means.\nManage transactions using COMMIT and ROLLBACK.\nHow to perform SQL full-text search using MATCH.\nUse SQLite CLI commands, such as .schema, .table, .headers on/off, .mode column.\nNormalize database schemas using BCNF and 4NF.",
    "crumbs": [
      "Content",
      "Week 05: Advanced SQL & Integrity Constraints (under construction)"
    ]
  },
  {
    "objectID": "week05.html#slides-videos-and-application-exercises",
    "href": "week05.html#slides-videos-and-application-exercises",
    "title": "Week 05: Advanced SQL & Integrity Constraints (under construction)",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 05: Slides\n\nSlides\n\n\nNo readings for Week 05.\n\n\n\n\nHomework 05: No homework for Week 05\n\n\n\nProject 05: No Project for Week 05",
    "crumbs": [
      "Content",
      "Week 05: Advanced SQL & Integrity Constraints (under construction)"
    ]
  },
  {
    "objectID": "week02-summary.html",
    "href": "week02-summary.html",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nPerform data aggregation using GROUP BY and HAVING.\nWrite and execute INNER, LEFT-OUTER, RIGHT, and FULL JOINs.\nConstruct subqueries for complex queries.\nImplement SQL functions and expressions.\nUse SQL best practices for readable and efficient queries.\nOptimize SQL queries for better performance."
  },
  {
    "objectID": "week02-summary.html#slos-for-week-02",
    "href": "week02-summary.html#slos-for-week-02",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "",
    "text": "At the end of this unit, students will be able to‚Ä¶\n\nPerform data aggregation using GROUP BY and HAVING.\nWrite and execute INNER, LEFT-OUTER, RIGHT, and FULL JOINs.\nConstruct subqueries for complex queries.\nImplement SQL functions and expressions.\nUse SQL best practices for readable and efficient queries.\nOptimize SQL queries for better performance."
  },
  {
    "objectID": "week02-summary.html#aggregation-grouping",
    "href": "week02-summary.html#aggregation-grouping",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "üìè 1. Aggregation & Grouping",
    "text": "üìè 1. Aggregation & Grouping\n\nCOUNT(), SUM(), AVG(), MIN(), MAX() ‚Äì summarize column values\nGROUP BY ‚Äì group rows by one or more columns\nHAVING ‚Äì filter grouped results\n\nSELECT department, AVG(gpa)\nFROM students\nGROUP BY department\nHAVING AVG(gpa) &gt; 3.5;"
  },
  {
    "objectID": "week02-summary.html#sql-joins",
    "href": "week02-summary.html#sql-joins",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "üîó 2. SQL Joins",
    "text": "üîó 2. SQL Joins\n\nINNER JOIN ‚Äì only matching rows from both tables\nLEFT OUTER JOIN ‚Äì all from left table + matching right\nRIGHT OUTER JOIN ‚Äì all from right table + matching left\nFULL OUTER JOIN ‚Äì all rows from both tables (if supported)\n\nSELECT s.name, c.name\nFROM students s\nLEFT JOIN enrollments e ON s.id = e.student_id\nLEFT JOIN courses c ON e.course_id = c.id;"
  },
  {
    "objectID": "week02-summary.html#subqueries",
    "href": "week02-summary.html#subqueries",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "üîç 3. Subqueries",
    "text": "üîç 3. Subqueries\n\nUse queries inside other queries\nUse with IN, EXISTS, =, &lt;, etc.\n\nSELECT * FROM students\nWHERE id IN (SELECT student_id FROM enrollments);\n\nCorrelated Subqueries: Reference outer query\nNon-Correlated Subqueries: Can run independently"
  },
  {
    "objectID": "week02-summary.html#sql-functions-expressions",
    "href": "week02-summary.html#sql-functions-expressions",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "üß≤ 4. SQL Functions & Expressions",
    "text": "üß≤ 4. SQL Functions & Expressions\n\nMath: ROUND(gpa, 2), ABS(), CEIL(), FLOOR()\nString: UPPER(), LOWER(), LENGTH(), SUBSTR()\nDate (SQLite): DATE(), STRFTIME('%Y', birthdate)\n\nSELECT UPPER(first_name) || ' ' || UPPER(last_name) FROM students;"
  },
  {
    "objectID": "week02-summary.html#sql-best-practices",
    "href": "week02-summary.html#sql-best-practices",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "ü™ú 5. SQL Best Practices",
    "text": "ü™ú 5. SQL Best Practices\n\nUse clear formatting and indentation\nAvoid SELECT * ‚Äì specify needed columns\nUse aliases (AS) to clarify column and table names\n\nSELECT s.first_name AS student, c.name AS course\nFROM students s JOIN enrollments e ON s.id = e.student_id;"
  },
  {
    "objectID": "week02-summary.html#query-optimization-basics",
    "href": "week02-summary.html#query-optimization-basics",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "‚ö° 6. Query Optimization Basics",
    "text": "‚ö° 6. Query Optimization Basics\n\nIndexes speed up filtering and joining\nFilter early with WHERE\nAvoid nested subqueries unless needed\nUse EXPLAIN (in supported engines) to analyze performance\n\nEXPLAIN SELECT * FROM students WHERE gpa &gt; 3.5;"
  },
  {
    "objectID": "week02-summary.html#pro-tip-practice-readability-matter",
    "href": "week02-summary.html#pro-tip-practice-readability-matter",
    "title": "Week 02: SQL ‚Äì Intermediate Concepts Summary",
    "section": "‚úÖ Pro Tip: Practice & Readability Matter!",
    "text": "‚úÖ Pro Tip: Practice & Readability Matter!\nGood SQL is not just correct‚Äîit‚Äôs efficient, maintainable, and easy to understand."
  },
  {
    "objectID": "jupyter/libraries/libraries.html",
    "href": "jupyter/libraries/libraries.html",
    "title": "CS 354 ‚Äì Database Management Systems",
    "section": "",
    "text": "!uv pip install sql !uv pip install ipython-sql\n\n%%capture\n%load_ext sql\n%sql sqlite:///library.db\n%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n\n\n%%sql\n-- Listing 9-1: Creating and filling the 2018 Public Libraries Survey table\n\n\nDROP TABLE IF EXISTS pls_fy2018_libraries;\n\nCREATE TABLE pls_fy2018_libraries (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n    county text NOT NULL,\n    phone text NOT NULL,\n    c_relatn text NOT NULL,\n    c_legbas text NOT NULL,\n    c_admin text NOT NULL,\n    c_fscs text NOT NULL,\n    geocode text NOT NULL,\n    lsabound text NOT NULL,\n    startdate text NOT NULL,\n    enddate text NOT NULL,\n    popu_lsa integer NOT NULL,\n    popu_und integer NOT NULL,\n    centlib integer NOT NULL,\n    branlib integer NOT NULL,\n    bkmob integer NOT NULL,\n    totstaff numeric(8,2) NOT NULL,\n    bkvol integer NOT NULL,\n    ebook integer NOT NULL,\n    audio_ph integer NOT NULL,\n    audio_dl integer NOT NULL,\n    video_ph integer NOT NULL,\n    video_dl integer NOT NULL,\n    ec_lo_ot integer NOT NULL,\n    subscrip integer NOT NULL,\n    hrs_open integer NOT NULL,\n    visits integer NOT NULL,\n    reference integer NOT NULL,\n    regbor integer NOT NULL,\n    totcir integer NOT NULL,\n    kidcircl integer NOT NULL,\n    totpro integer NOT NULL,\n    gpterms integer NOT NULL,\n    pitusr integer NOT NULL,\n    wifisess integer NOT NULL,\n    obereg text NOT NULL,\n    statstru text NOT NULL,\n    statname text NOT NULL,\n    stataddr text NOT NULL,\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\nimport subprocess\ndb = ‚Äúlibrary.db‚Äù csv = ‚Äúpls_fy2018_libraries.csv‚Äù table = ‚Äúpls_fy2018_libraries‚Äù\nsqlite_command = f‚Äù‚Äú‚Äù .mode csv .import ‚Äò{csv}‚Äô {table} ‚Äú‚Äú‚Äù\nsubprocess.run([‚Äúsqlite3‚Äù, db], input=sqlite_command, text=True)\n\n%%sql\nmode csv\nimport --skip 1 pls_fy2018_libraries.csv pls_fy2018_libraries\n\n\n%%sql\nSELECT * FROM pls_fy2018_libraries\n\n\n%%sh\n./importCSV.sh pls_fy2018_libraries.csv library.db pls_fy2018_libraries\n\n\n%%sql\nSELECT * FROM pls_fy2018_libraries\nLIMIT 5;\n\n\n%%sql\nCREATE INDEX libname_2018_idx ON pls_fy2018_libraries (libname);\n\n\n%%sql\nSELECT * FROM pls_fy2018_libraries LIMIT 5;\n\n\n%%sql\nPRAGMA index_list('pls_fy2018_libraries');\n\n\n%%sql\nSELECT sql FROM sqlite_master WHERE type = 'index' AND name = 'libname_2018_idx';\n\n\n%%sql\nSELECT count(*)\nFROM pls_fy2018_libraries;\n\n\n%%sql\nSELECT count(phone)\nFROM pls_fy2018_libraries;\n\n\n%%sql \nSELECT libname, count(libname)\n    FROM pls_fy2018_libraries\n    GROUP BY libname\n    ORDER BY count(libname) DESC\n    LIMIT 20;\n\n\n%%sql\nSELECT max(visits), min(visits)\nFROM pls_fy2018_libraries\nWHERE visits &gt; 0;"
  },
  {
    "objectID": "week03.html",
    "href": "week03.html",
    "title": "Week 03: SQL ‚Äì Data Modification & Advanced Queries (under construction)",
    "section": "",
    "text": "Students will be able to:\n\nUse SQL aggregate and scalar functions and create expressions.\nWork with data types, including dates and strings, using LIKE, GLOB,DATE, TIME, DATETIME, JULIANDAY and STRFTIME. Notebook 3.2\nManipulate the records stored in a database using INSERT INTO, UPDATE and DELETE FROM , REPLACE, UPSERT and RETURNING.\nTable design principles using DDL commands, such as CREATE TABLE, DROP TABLE, ALTER TABLE, CREATE INDEX, DROP INDEX, CREATE VIEW, DROP VIEW.\nControl columns values using constraints: primary keys, foreign keys, delete with CASCADE, CHECK, UNIQUE, NOT NULL, AUTOINCREMENT.\nCreate and manage indexes to optimize query performance using performance and debug commands, such as CREATE INDEX, ANALYZE and EXPLAIN. Notebook 3.6\nOptimizing database files with VACUUM.",
    "crumbs": [
      "Content",
      "Week 03: SQL ‚Äì Data Modification & Advanced Queries (under construction)"
    ]
  },
  {
    "objectID": "week03.html#slos-for-week-03",
    "href": "week03.html#slos-for-week-03",
    "title": "Week 03: SQL ‚Äì Data Modification & Advanced Queries (under construction)",
    "section": "",
    "text": "Students will be able to:\n\nUse SQL aggregate and scalar functions and create expressions.\nWork with data types, including dates and strings, using LIKE, GLOB,DATE, TIME, DATETIME, JULIANDAY and STRFTIME. Notebook 3.2\nManipulate the records stored in a database using INSERT INTO, UPDATE and DELETE FROM , REPLACE, UPSERT and RETURNING.\nTable design principles using DDL commands, such as CREATE TABLE, DROP TABLE, ALTER TABLE, CREATE INDEX, DROP INDEX, CREATE VIEW, DROP VIEW.\nControl columns values using constraints: primary keys, foreign keys, delete with CASCADE, CHECK, UNIQUE, NOT NULL, AUTOINCREMENT.\nCreate and manage indexes to optimize query performance using performance and debug commands, such as CREATE INDEX, ANALYZE and EXPLAIN. Notebook 3.6\nOptimizing database files with VACUUM.",
    "crumbs": [
      "Content",
      "Week 03: SQL ‚Äì Data Modification & Advanced Queries (under construction)"
    ]
  },
  {
    "objectID": "week03.html#slides-videos-and-application-exercises",
    "href": "week03.html#slides-videos-and-application-exercises",
    "title": "Week 03: SQL ‚Äì Data Modification & Advanced Queries (under construction)",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nWeek 03: Slides\n\n\nMark Simon. (2023). Getting Started with SQL and Databases‚ÄØ: Managing and Manipulating Data with SQL. Apress. - Chapters 7, 8 and 9\n\n\n\n\nHomework 03:\n\nInstructions\n\n\n\n\nProject 03: Classes\n\nInstructions",
    "crumbs": [
      "Content",
      "Week 03: SQL ‚Äì Data Modification & Advanced Queries (under construction)"
    ]
  }
]